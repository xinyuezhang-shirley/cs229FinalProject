{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/xinyuezhang-shirley/cs229FinalProject/blob/main/CS229_ProjectionLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvcom4jd77aj"
   },
   "source": [
    "Final Product. Rest of the Notebooks are mainly for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 128                \n",
    "EPOCHS = 500              # maximum epochs (early stop may cut short)\n",
    "LR = 2e-3                 # base learning rate (after warmup)\n",
    "TEMP = 0.7                # InfoNCE temperature\n",
    "SAMPLES_PER_EPOCH = 2500   # samples per epoch  \n",
    "\n",
    "# Learning rate schedule / early stopping\n",
    "WARMUP_EPOCHS = 5         # linear warmup epochs\n",
    "MIN_LR = 1e-3             # final minimum LR for cosine schedule\n",
    "USE_COSINE_SCHEDULE = True\n",
    "EARLY_STOP_PATIENCE = 25  # epochs (post-warmup) with no sufficient improvement\n",
    "EARLY_STOP_DELTA = 0.002  # required loss decrease to reset patience\n",
    "MOVING_AVG_WINDOW = 10    # for smoothed loss\n",
    "\n",
    "# Modality weights (kept same)\n",
    "ALPHA = 0.6       # MPNet branch\n",
    "BETA_EMO = 0.1    # emotion semantics\n",
    "BETA_THEME = 0.15 # theme semantics\n",
    "BETA_OTHER = 0.1  # other semantics (sentiment, subjectivity, concreteness, energy, narrative, imagery)\n",
    "GAMMA = 0.15      # structural/lexical branch\n",
    "\n",
    "# Unsupervised pair construction hyperparameters\n",
    "POS_TOPK = 5        # positives per poem from similarity\n",
    "HARD_TOPK = 0       # hard negatives per poem (near misses)\n",
    "EASY_THRESHOLD = 0.25  # cosine threshold for easy negatives (set None to disable absolute cutoff)\n",
    "EASY_NEG_PERCENTILE = 0.05  # fallback percentile (per poem) for easy negatives\n",
    "EASY_NEG_SAMPLES = 5        # max easy negatives sampled per poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcT0UQyQn9qU",
    "outputId": "04956265-cf14-42f1-bd85-05563014d01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poems: 3413 items\n",
      "Songs (cleaned): 2995 items\n",
      "poem_vecs: (3413, 768), song_vecs: (2995, 768)\n",
      "poem_feats: (3413, 6), song_feats: (2995, 6)\n",
      "poem_sem (emo/theme/other): (3413, 9), (3413, 10), (3413, 17)\n",
      "song_sem (emo/theme/other): (2995, 9), (2995, 10), (2995, 17)\n"
     ]
    }
   ],
   "source": [
    "# MPNet embeddings (raw, not yet filtered)\n",
    "poem_vecs = np.load(\"data/processed/mpnet_embeddings_poems.npy\")\n",
    "song_vecs_raw = np.load(\"data/processed/mpnet_embeddings_songs.npy\")\n",
    "\n",
    "# Load all features from full_features.npz\n",
    "full = np.load(\"data/processed/full_features.npz\", allow_pickle=True)\n",
    "\n",
    "# Structural + lexical features (concatenated)\n",
    "poem_struct = full[\"poem_struct\"]  # (3413, 3)\n",
    "poem_lexical = full[\"poem_lexical\"]  # (3413, 3)\n",
    "poem_feats = np.concatenate([poem_struct, poem_lexical], axis=1)  # (3413, 6)\n",
    "\n",
    "song_struct = full[\"song_struct\"]  # (2995, 4)\n",
    "song_lexical = full[\"song_lexical\"]  # (2995, 3)\n",
    "# For songs, only use first 3 sestructural features to match poems (exclude WPM)\n",
    "song_feats = np.concatenate([song_struct[:, :3], song_lexical], axis=1)  # (2995, 6)\n",
    "\n",
    "# Semantic features\n",
    "poem_sem_all = full[\"poem_semantic\"]  # (3413, 36)\n",
    "song_sem_all = full[\"song_semantic\"]  # (2995, 36)\n",
    "\n",
    "# Split semantic features by groups\n",
    "# emotions(9): 0-9, themes(10): 9-19, other(17): 19-36\n",
    "poem_sem_emo   = poem_sem_all[:, 0:9]\n",
    "poem_sem_theme = poem_sem_all[:, 9:19]\n",
    "poem_sem_other = poem_sem_all[:, 19:36]\n",
    "song_sem_emo   = song_sem_all[:, 0:9]\n",
    "song_sem_theme = song_sem_all[:, 9:19]\n",
    "song_sem_other = song_sem_all[:, 19:36]\n",
    "\n",
    "# Align song embeddings to match cleaned features\n",
    "idx_map = full[\"song_source_indexes\"]  # (2995,) maps cleaned songs -> raw embedding indices\n",
    "song_vecs = song_vecs_raw[idx_map]  # reorder raw embeddings to match cleaned data\n",
    "\n",
    "print(f\"Poems: {poem_vecs.shape[0]} items\")\n",
    "print(f\"Songs (cleaned): {song_vecs.shape[0]} items\")\n",
    "print(f\"poem_vecs: {poem_vecs.shape}, song_vecs: {song_vecs.shape}\")\n",
    "print(f\"poem_feats: {poem_feats.shape}, song_feats: {song_feats.shape}\")\n",
    "print(f\"poem_sem (emo/theme/other): {poem_sem_emo.shape}, {poem_sem_theme.shape}, {poem_sem_other.shape}\")\n",
    "print(f\"song_sem (emo/theme/other): {song_sem_emo.shape}, {song_sem_theme.shape}, {song_sem_other.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poem branches: (3413, 768) (3413, 9) (3413, 10) (3413, 17) (3413, 6)\n",
      "song  branches: (2995, 768) (2995, 9) (2995, 10) (2995, 17) (2995, 6)\n",
      "Computing mpnet cosine matrix on GPU...\n",
      "Computing sem_emo cosine matrix on GPU...\n",
      "Computing sem_theme cosine matrix on GPU...\n",
      "Computing sem_other cosine matrix on GPU...\n",
      "Computing feat cosine matrix on GPU...\n",
      "Combined cosine matrix shape: torch.Size([3413, 2995])\n",
      "Building pairs with POS_TOPK=5, HARD_TOPK=0, EASY_THRESHOLD=0.25, EASY_NEG_PERCENTILE=0.05...\n",
      "Built pairs -> pos: 17065 hard: 0 easy: 16869\n"
     ]
    }
   ],
   "source": [
    "# Normalize MPNet embeddings per row to balance scales\n",
    "poem_vecs = poem_vecs / (np.linalg.norm(poem_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "song_vecs = song_vecs / (np.linalg.norm(song_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "song_vecs_raw_norm = song_vecs_raw / (np.linalg.norm(song_vecs_raw, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Build branch inputs\n",
    "poem_in = {\n",
    "    \"mpnet\": poem_vecs.astype(np.float32),\n",
    "    \"sem_emo\":   poem_sem_emo.astype(np.float32),\n",
    "    \"sem_theme\": poem_sem_theme.astype(np.float32),\n",
    "    \"sem_other\": poem_sem_other.astype(np.float32),\n",
    "    \"feat\":  poem_feats.astype(np.float32),\n",
    "}\n",
    "song_in = {\n",
    "    \"mpnet\": song_vecs.astype(np.float32),\n",
    "    \"sem_emo\":   song_sem_emo.astype(np.float32),\n",
    "    \"sem_theme\": song_sem_theme.astype(np.float32),\n",
    "    \"sem_other\": song_sem_other.astype(np.float32),\n",
    "    \"feat\":  song_feats.astype(np.float32),\n",
    "}\n",
    "\n",
    "def _row_norm(x):\n",
    "    return x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "print(\"poem branches:\", poem_in[\"mpnet\"].shape, poem_in[\"sem_emo\"].shape, poem_in[\"sem_theme\"].shape, poem_in[\"sem_other\"].shape, poem_in[\"feat\"].shape)\n",
    "print(\"song  branches:\", song_in[\"mpnet\"].shape, song_in[\"sem_emo\"].shape, song_in[\"sem_theme\"].shape, song_in[\"sem_other\"].shape, song_in[\"feat\"].shape)\n",
    "\n",
    "# Compute pairwise cosine matrices per modality and combine with weights\n",
    "import torch\n",
    "\n",
    "def get_cosine_matrix(p_feat, s_feat, name):\n",
    "    print(f\"Computing {name} cosine matrix on GPU...\")\n",
    "    p_norm = torch.from_numpy(_row_norm(p_feat)).to(torch.float32).to(DEVICE)\n",
    "    s_norm = torch.from_numpy(_row_norm(s_feat)).to(torch.float32).to(DEVICE)\n",
    "    return torch.matmul(p_norm, s_norm.T)\n",
    "\n",
    "cos_mpnet = get_cosine_matrix(poem_in[\"mpnet\"], song_in[\"mpnet\"], \"mpnet\")\n",
    "cos_emo   = get_cosine_matrix(poem_in[\"sem_emo\"], song_in[\"sem_emo\"], \"sem_emo\")\n",
    "cos_theme = get_cosine_matrix(poem_in[\"sem_theme\"], song_in[\"sem_theme\"], \"sem_theme\")\n",
    "cos_other = get_cosine_matrix(poem_in[\"sem_other\"], song_in[\"sem_other\"], \"sem_other\")\n",
    "cos_feat  = get_cosine_matrix(poem_in[\"feat\"], song_in[\"feat\"], \"feat\")\n",
    "\n",
    "cos_matrix_t = (\n",
    "    ALPHA * cos_mpnet +\n",
    "    BETA_EMO * cos_emo +\n",
    "    BETA_THEME * cos_theme +\n",
    "    BETA_OTHER * cos_other +\n",
    "    GAMMA * cos_feat\n",
    ")\n",
    "\n",
    "print(\"Combined cosine matrix shape:\", cos_matrix_t.shape)\n",
    "\n",
    "# Build pos/hard/neg pairs from current hyperparameters (always recompute based on thresholds)\n",
    "print(\n",
    "    f\"Building pairs with POS_TOPK={POS_TOPK}, HARD_TOPK={HARD_TOPK}, \"\n",
    "    f\"EASY_THRESHOLD={EASY_THRESHOLD}, EASY_NEG_PERCENTILE={EASY_NEG_PERCENTILE}...\"\n",
    " )\n",
    "P, S = cos_matrix_t.shape\n",
    "pos_pairs = []\n",
    "hard_pairs = []\n",
    "neg_pairs = []\n",
    "\n",
    "easy_mask = None\n",
    "percentile_vals = None\n",
    "if EASY_THRESHOLD is not None:\n",
    "    easy_mask = cos_matrix_t <= EASY_THRESHOLD\n",
    "if EASY_NEG_PERCENTILE is not None:\n",
    "    percentile_vals = torch.quantile(cos_matrix_t, EASY_NEG_PERCENTILE, dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_topk = POS_TOPK + HARD_TOPK\n",
    "    topk_idxs = None\n",
    "    if total_topk > 0:\n",
    "        _, topk_idxs = torch.topk(\n",
    "            cos_matrix_t,\n",
    "            k=min(S, total_topk),\n",
    "            dim=1,\n",
    "            largest=True,\n",
    "            sorted=True,\n",
    "        )\n",
    "\n",
    "    # Build pos and hard lists\n",
    "    if topk_idxs is not None:\n",
    "        for i in range(P):\n",
    "            if POS_TOPK > 0:\n",
    "                pos_pairs.extend([(int(i), int(j)) for j in topk_idxs[i, :POS_TOPK].tolist()])\n",
    "            if HARD_TOPK > 0:\n",
    "                hard_pairs.extend(\n",
    "                    [(int(i), int(j)) for j in topk_idxs[i, POS_TOPK : POS_TOPK + HARD_TOPK].tolist()]\n",
    "                )\n",
    "\n",
    "    for i in range(P):\n",
    "        low_idxs = None\n",
    "        if easy_mask is not None:\n",
    "            mask_idxs = torch.nonzero(easy_mask[i], as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "            if mask_idxs.size > 0:\n",
    "                low_idxs = mask_idxs\n",
    "        if (low_idxs is None or low_idxs.size == 0) and percentile_vals is not None:\n",
    "            thresh = percentile_vals[i].item()\n",
    "            mask_idxs = torch.nonzero(cos_matrix_t[i] <= thresh, as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "            if mask_idxs.size > 0:\n",
    "                low_idxs = mask_idxs\n",
    "        if low_idxs is None or low_idxs.size == 0:\n",
    "            continue\n",
    "        sample_ct = min(EASY_NEG_SAMPLES, low_idxs.size)\n",
    "        choice = np.random.choice(low_idxs, size=sample_ct, replace=False)\n",
    "        for j in choice:\n",
    "            neg_pairs.append((int(i), int(j)))\n",
    "\n",
    "print(f\"Built pairs -> pos: {len(pos_pairs)} hard: {len(hard_pairs)} easy: {len(neg_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46 raw triplets from data/Song_Poem.xlsx. Mapped 46 to cleaned song indices (skipped 0 for missing songs, skipped 4 for invalid labels).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "triplet_sheet = Path(\"data/Song_Poem.xlsx\")\n",
    "human_triplets = []  # cleaned song indices aligned with song_gpu\n",
    "human_triplets_raw = []  # original raw song indices from the sheet\n",
    "if not triplet_sheet.exists():\n",
    "    raise FileNotFoundError(f\"Missing human eval sheet at {triplet_sheet}. Upload it before running the grid search.\")\n",
    "\n",
    "def _find_col(df, keyword):\n",
    "    keyword = keyword.lower()\n",
    "    for col in df.columns:\n",
    "        if keyword in str(col).lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "triplet_df = pd.read_excel(triplet_sheet)\n",
    "label_col = _find_col(triplet_df, \"song number\")\n",
    "song1_col = _find_col(triplet_df, \"song 1\")\n",
    "song2_col = _find_col(triplet_df, \"song 2\")\n",
    "poem_col = _find_col(triplet_df, \"poem\")\n",
    "if None in (label_col, song1_col, song2_col, poem_col):\n",
    "    raise RuntimeError(\n",
    "        f\"Could not locate required columns in {triplet_sheet.name}. \"\n",
    "        f\"Found columns: {list(triplet_df.columns)}\"\n",
    "    )\n",
    "\n",
    "triplet_df = triplet_df[[label_col, poem_col, song1_col, song2_col]].copy()\n",
    "triplet_df.columns = [\"label\", \"poem_idx\", \"song1_raw\", \"song2_raw\"]\n",
    "triplet_df = triplet_df.dropna(subset=[\"label\", \"poem_idx\", \"song1_raw\", \"song2_raw\"])\n",
    "triplet_df[\"label\"] = triplet_df[\"label\"].astype(str).str.strip()\n",
    "\n",
    "raw_to_clean_song = {int(raw): int(clean) for clean, raw in enumerate(idx_map)}\n",
    "skipped_missing = 0\n",
    "skipped_label = 0\n",
    "\n",
    "for _, row in triplet_df.iterrows():\n",
    "    label_str = row[\"label\"]\n",
    "    if label_str.lower() in (\"unclear\", \"\", \"nan\"):\n",
    "        skipped_label += 1\n",
    "        continue\n",
    "    try:\n",
    "        label = int(float(label_str))\n",
    "    except ValueError:\n",
    "        skipped_label += 1\n",
    "        continue\n",
    "    if label not in (1, 2):\n",
    "        skipped_label += 1\n",
    "        continue\n",
    "    poem_idx = int(row[\"poem_idx\"])\n",
    "    song1_raw = int(row[\"song1_raw\"])\n",
    "    song2_raw = int(row[\"song2_raw\"])\n",
    "    human_triplets_raw.append((poem_idx, song1_raw, song2_raw, label))\n",
    "    if song1_raw not in raw_to_clean_song or song2_raw not in raw_to_clean_song:\n",
    "        skipped_missing += 1\n",
    "        continue\n",
    "    song1_clean = raw_to_clean_song[song1_raw]\n",
    "    song2_clean = raw_to_clean_song[song2_raw]\n",
    "    human_triplets.append((poem_idx, song1_clean, song2_clean, label))\n",
    "\n",
    "if not human_triplets:\n",
    "    raise RuntimeError(\"No valid human triplets were loaded after remapping; check the evaluation sheet contents.\")\n",
    "print(\n",
    "    f\"Loaded {len(human_triplets_raw)} raw triplets from {triplet_sheet}. \"\n",
    "    f\"Mapped {len(human_triplets)} to cleaned song indices (skipped {skipped_missing} for missing songs, \"\n",
    "    f\"skipped {skipped_label} for invalid labels).\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pos_pairs, neg_pairs, hard_pairs, size):\n",
    "        \"\"\"Return poem/song indices for each sampled pair.\"\"\"\n",
    "        self.pos_pairs = pos_pairs\n",
    "        self.neg_pairs = neg_pairs\n",
    "        self.hard_pairs = hard_pairs\n",
    "        self.size = size\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self, idx):\n",
    "        i_poem, j_song = self.pos_pairs[np.random.randint(len(self.pos_pairs))]\n",
    "        return i_poem, j_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2500 samples/epoch, loader batches: 20\n"
     ]
    }
   ],
   "source": [
    "# Pre-build GPU tensors so batching is instant\n",
    "poem_gpu = {}\n",
    "song_gpu = {}\n",
    "\n",
    "for k in poem_in:\n",
    "    poem_gpu[k] = torch.from_numpy(poem_in[k]).to(torch.float32).to(DEVICE)\n",
    "    song_gpu[k] = torch.from_numpy(song_in[k]).to(torch.float32).to(DEVICE)\n",
    "\n",
    "# Build dataset and loader\n",
    "dataset = PairDataset(pos_pairs, neg_pairs, hard_pairs, size=SAMPLES_PER_EPOCH)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples/epoch, loader batches: {len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_loss(poem_emb, song_emb, temperature=TEMP):\n",
    "    \"\"\"\n",
    "    InfoNCE / contrastive loss for a batch of poem/song embedding pairs.\n",
    "    \n",
    "    Args:\n",
    "        poem_emb: [B, D] poem embeddings\n",
    "        song_emb: [B, D] song embeddings\n",
    "        temperature: scaling for logits\n",
    "    \n",
    "    Returns:\n",
    "        Scalar loss\n",
    "    \"\"\"\n",
    "    # Normalize both\n",
    "    poem_emb = F.normalize(poem_emb, dim=1)\n",
    "    song_emb = F.normalize(song_emb, dim=1)\n",
    "    \n",
    "    B = poem_emb.shape[0]\n",
    "    \n",
    "    # Compute all-pairs similarity: [B, B]\n",
    "    logits = torch.matmul(poem_emb, song_emb.T) / temperature\n",
    "    \n",
    "    # Positives on diagonal, negatives off-diagonal\n",
    "    labels = torch.arange(B, device=poem_emb.device)\n",
    "    \n",
    "    # Symmetric loss: poem->song + song->poem\n",
    "    loss_p2s = F.cross_entropy(logits, labels)\n",
    "    loss_s2p = F.cross_entropy(logits.T, labels)\n",
    "    \n",
    "    return (loss_p2s + loss_s2p) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x7U7AM1ToG3D"
   },
   "outputs": [],
   "source": [
    "class ProjectionModel(nn.Module):\n",
    "    def __init__(self, p_dims, s_dims, proj_dim):\n",
    "        super().__init__()\n",
    "        self.p_mp, self.p_emo, self.p_theme, self.p_other, self.p_ft = p_dims\n",
    "        self.s_mp, self.s_emo, self.s_theme, self.s_other, self.s_ft = s_dims\n",
    "        # poem branches\n",
    "        self.poem_mp = nn.Sequential(nn.Linear(self.p_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.poem_emo = nn.Sequential(nn.Linear(max(self.p_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_theme = nn.Sequential(nn.Linear(max(self.p_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_other = nn.Sequential(nn.Linear(max(self.p_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_ft = nn.Sequential(nn.Linear(self.p_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "        # song branches\n",
    "        self.song_mp = nn.Sequential(nn.Linear(self.s_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.song_emo = nn.Sequential(nn.Linear(max(self.s_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_theme = nn.Sequential(nn.Linear(max(self.s_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_other = nn.Sequential(nn.Linear(max(self.s_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_ft = nn.Sequential(nn.Linear(self.s_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "    def forward_poem(self, p):\n",
    "        mp = self.poem_mp(p[\"mpnet\"])\n",
    "        emo_in = p[\"sem_emo\"] if self.p_emo > 0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        theme_in = p[\"sem_theme\"] if self.p_theme > 0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        other_in = p[\"sem_other\"] if self.p_other > 0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        emo = self.poem_emo(emo_in)\n",
    "        theme = self.poem_theme(theme_in)\n",
    "        other = self.poem_other(other_in)\n",
    "        ft  = self.poem_ft(p[\"feat\"])\n",
    "        comb = torch.cat([mp, emo, theme, other, ft], dim=1)\n",
    "        z = self.poem_proj(comb)\n",
    "        return F.normalize(z, dim=1)\n",
    "    def forward_song(self, s):\n",
    "        mp = self.song_mp(s[\"mpnet\"])\n",
    "        emo_in = s[\"sem_emo\"] if self.s_emo > 0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        theme_in = s[\"sem_theme\"] if self.s_theme > 0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        other_in = s[\"sem_other\"] if self.s_other > 0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        emo = self.song_emo(emo_in)\n",
    "        theme = self.song_theme(theme_in)\n",
    "        other = self.song_other(other_in)\n",
    "        ft  = self.song_ft(s[\"feat\"])\n",
    "        comb = torch.cat([mp, emo, theme, other, ft], dim=1)\n",
    "        z = self.song_proj(comb)\n",
    "        return F.normalize(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper utilities for grid search experiments (pair building, training, evaluation)\n",
    "from itertools import product\n",
    "import time\n",
    "import math\n",
    "\n",
    "P_DIMS_GRID = (\n",
    "    poem_gpu[\"mpnet\"].shape[1],\n",
    "    poem_gpu[\"sem_emo\"].shape[1] if poem_gpu[\"sem_emo\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"sem_theme\"].shape[1] if poem_gpu[\"sem_theme\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"sem_other\"].shape[1] if poem_gpu[\"sem_other\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"feat\"].shape[1],\n",
    ")\n",
    "S_DIMS_GRID = (\n",
    "    song_gpu[\"mpnet\"].shape[1],\n",
    "    song_gpu[\"sem_emo\"].shape[1] if song_gpu[\"sem_emo\"].ndim > 1 else 0,\n",
    "    song_gpu[\"sem_theme\"].shape[1] if song_gpu[\"sem_theme\"].ndim > 1 else 0,\n",
    "    song_gpu[\"sem_other\"].shape[1] if song_gpu[\"sem_other\"].ndim > 1 else 0,\n",
    "    song_gpu[\"feat\"].shape[1],\n",
    ")\n",
    "PROJ_DIM_GRID = int(\n",
    "    globals().get(\n",
    "        \"proj_dim\",\n",
    "        getattr(model.poem_proj[-1], \"out_features\", 128) if \"model\" in globals() else 128,\n",
    "    )\n",
    ")\n",
    "\n",
    "def combine_cosine_matrix(weights):\n",
    "    \"\"\"Create weighted cosine matrix using cached per-modality similarities.\"\"\"\n",
    "    return (\n",
    "        weights[\"alpha\"] * cos_mpnet\n",
    "        + weights[\"beta_emo\"] * cos_emo\n",
    "        + weights[\"beta_theme\"] * cos_theme\n",
    "        + weights[\"beta_other\"] * cos_other\n",
    "        + weights[\"gamma\"] * cos_feat\n",
    "    )\n",
    "\n",
    "def build_pairs_from_matrix(\n",
    "    cos_matrix,\n",
    "    pos_topk=POS_TOPK,\n",
    "    hard_topk=HARD_TOPK,\n",
    "    easy_threshold=EASY_THRESHOLD,\n",
    "    easy_percentile=EASY_NEG_PERCENTILE,\n",
    "    easy_samples=EASY_NEG_SAMPLES,\n",
    "    rng=None,\n",
    "):\n",
    "    \"\"\"Return positive / hard / easy pairs based on similarity thresholds.\"\"\"\n",
    "    rng = rng or np.random\n",
    "    P, S = cos_matrix.shape\n",
    "    pos_pairs, hard_pairs, neg_pairs = [], [], []\n",
    "    easy_mask = None\n",
    "    percentile_vals = None\n",
    "    if easy_threshold is not None:\n",
    "        easy_mask = cos_matrix <= easy_threshold\n",
    "    if easy_percentile is not None:\n",
    "        percentile_vals = torch.quantile(cos_matrix, easy_percentile, dim=1)\n",
    "    with torch.no_grad():\n",
    "        total_topk = pos_topk + hard_topk\n",
    "        topk_idxs = None\n",
    "        if total_topk > 0:\n",
    "            _, topk_idxs = torch.topk(\n",
    "                cos_matrix,\n",
    "                k=min(S, total_topk),\n",
    "                dim=1,\n",
    "                largest=True,\n",
    "                sorted=True,\n",
    "            )\n",
    "        if topk_idxs is not None:\n",
    "            for i in range(P):\n",
    "                if pos_topk > 0:\n",
    "                    pos_pairs.extend([(int(i), int(j)) for j in topk_idxs[i, :pos_topk].tolist()])\n",
    "                if hard_topk > 0:\n",
    "                    hard_pairs.extend(\n",
    "                        [(int(i), int(j)) for j in topk_idxs[i, pos_topk : pos_topk + hard_topk].tolist()]\n",
    "                    )\n",
    "        for i in range(P):\n",
    "            low_idxs = None\n",
    "            if easy_mask is not None:\n",
    "                mask_idxs = torch.nonzero(easy_mask[i], as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "                if mask_idxs.size > 0:\n",
    "                    low_idxs = mask_idxs\n",
    "            if (low_idxs is None or low_idxs.size == 0) and percentile_vals is not None:\n",
    "                thresh = percentile_vals[i].item()\n",
    "                mask_idxs = torch.nonzero(cos_matrix[i] <= thresh, as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "                if mask_idxs.size > 0:\n",
    "                    low_idxs = mask_idxs\n",
    "            if low_idxs is None or low_idxs.size == 0:\n",
    "                continue\n",
    "            sample_ct = min(easy_samples, low_idxs.size)\n",
    "            choice = rng.choice(low_idxs, size=sample_ct, replace=False)\n",
    "            for j in choice:\n",
    "                neg_pairs.append((int(i), int(j)))\n",
    "    return pos_pairs, hard_pairs, neg_pairs\n",
    "\n",
    "def make_loader_for_config(pos_pairs, neg_pairs, hard_pairs, batch_size, samples_per_epoch):\n",
    "    dataset = PairDataset(pos_pairs, neg_pairs, hard_pairs, size=samples_per_epoch)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    return dataset, loader\n",
    "\n",
    "def train_single_config(\n",
    "    loader,\n",
    "    temperature,\n",
    "    lr,\n",
    "    epochs,\n",
    "    patience,\n",
    "    delta,\n",
    "    warmup_epochs,\n",
    "    min_lr,\n",
    "    use_cosine_schedule,\n",
    "    moving_avg_window,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"Train a ProjectionModel with the provided loader and hyperparameters.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    model_local = ProjectionModel(P_DIMS_GRID, S_DIMS_GRID, PROJ_DIM_GRID).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model_local.parameters(), lr=lr)\n",
    "    warm_epochs = min(warmup_epochs, epochs)\n",
    "    warmup_scheduler = None\n",
    "    scheduler_main = None\n",
    "    if use_cosine_schedule and epochs > 0:\n",
    "        warm_epochs = max(1, warm_epochs)\n",
    "        def lr_lambda(epoch):\n",
    "            return min(1.0, (epoch + 1) / warm_epochs)\n",
    "        warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "        t_max = max(1, epochs - warm_epochs)\n",
    "        scheduler_main = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=min_lr)\n",
    "    loss_history, lr_history = [], []\n",
    "    best_loss = math.inf\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        for pidxs, sidxs in loader:\n",
    "            optimizer.zero_grad()\n",
    "            batch_poem = {k: poem_gpu[k][pidxs] for k in poem_gpu}\n",
    "            batch_song = {k: song_gpu[k][sidxs] for k in song_gpu}\n",
    "            poem_out = model_local.forward_poem(batch_poem)\n",
    "            song_out = model_local.forward_song(batch_song)\n",
    "            loss = clip_loss(poem_out, song_out, temperature=temperature)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "        if not epoch_losses:\n",
    "            break\n",
    "        avg_loss = float(np.mean(epoch_losses))\n",
    "        loss_history.append(avg_loss)\n",
    "        window = moving_avg_window if moving_avg_window > 0 else len(loss_history)\n",
    "        smooth_loss = float(np.mean(loss_history[-window:]))\n",
    "        if smooth_loss < best_loss - delta:\n",
    "            best_loss = smooth_loss\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model_local.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if warmup_scheduler and epoch < warm_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        elif scheduler_main:\n",
    "            scheduler_main.step()\n",
    "        lr_history.append(optimizer.param_groups[0][\"lr\"])\n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    train_time = time.time() - start_time\n",
    "    if best_state:\n",
    "        model_local.load_state_dict(best_state)\n",
    "    return {\n",
    "        \"model\": model_local,\n",
    "        \"loss_history\": loss_history,\n",
    "        \"lr_history\": lr_history,\n",
    "        \"best_loss\": best_loss,\n",
    "        \"epochs_trained\": len(loss_history),\n",
    "        \"train_time\": train_time,\n",
    "    }\n",
    "\n",
    "def evaluate_on_triplets(model_local):\n",
    "    if \"human_triplets\" not in globals():\n",
    "        raise RuntimeError(\"human_triplets is not defined in the workspace.\")\n",
    "    model_local.eval()\n",
    "    correct = 0\n",
    "    total = len(human_triplets)\n",
    "    with torch.no_grad():\n",
    "        for p_idx, s1_idx, s2_idx, label in human_triplets:\n",
    "            p_batch = {k: poem_gpu[k][p_idx : p_idx + 1] for k in poem_gpu}\n",
    "            s1_batch = {k: song_gpu[k][s1_idx : s1_idx + 1] for k in song_gpu}\n",
    "            s2_batch = {k: song_gpu[k][s2_idx : s2_idx + 1] for k in song_gpu}\n",
    "            p_z = model_local.forward_poem(p_batch)\n",
    "            s1_z = model_local.forward_song(s1_batch)\n",
    "            s2_z = model_local.forward_song(s2_batch)\n",
    "            sim1 = float((p_z * s1_z).sum().item())\n",
    "            sim2 = float((p_z * s2_z).sum().item())\n",
    "            pred = 1 if sim1 > sim2 else 2\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Config 1/60 :: mpnet_heavy_bs96_t0.50_spe4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     68\u001b[39m pos_pairs, hard_pairs, neg_pairs = build_pairs_from_matrix(\n\u001b[32m     69\u001b[39m     cos_matrix,\n\u001b[32m     70\u001b[39m     pos_topk=cfg[\u001b[33m\"\u001b[39m\u001b[33mpos_topk\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     rng=rng,\n\u001b[32m     76\u001b[39m )\n\u001b[32m     77\u001b[39m _, loader_local = make_loader_for_config(\n\u001b[32m     78\u001b[39m     pos_pairs,\n\u001b[32m     79\u001b[39m     neg_pairs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     samples_per_epoch=cfg[\u001b[33m\"\u001b[39m\u001b[33msamples_per_epoch\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     83\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m train_out = \u001b[43mtrain_single_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdelta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwarmup_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin_lr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cosine_schedule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muse_cosine_schedule\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmoving_avg_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmoving_avg_window\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m triplet_acc = evaluate_on_triplets(train_out[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     98\u001b[39m result_row = {\n\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m: cfg[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    100\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: cfg[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhard_pairs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(hard_pairs),\n\u001b[32m    110\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mtrain_single_config\u001b[39m\u001b[34m(loader, temperature, lr, epochs, patience, delta, warmup_epochs, min_lr, use_cosine_schedule, moving_avg_window, seed)\u001b[39m\n\u001b[32m    141\u001b[39m     loss = clip_loss(poem_out, song_out, temperature=temperature)\n\u001b[32m    142\u001b[39m     loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     epoch_losses.append(loss.item())\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m epoch_losses:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m opt = opt_ref()\n\u001b[32m    132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cs229/lib/python3.11/site-packages/torch/optim/adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    533\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Grid search runner (toggle RUN_GRID_SEARCH to True to execute all configurations)\n",
    "import json\n",
    "\n",
    "RUN_GRID_SEARCH = True  # Notebook default: execute grid search when this cell runs\n",
    "SAVE_ALL_MODELS = True  # When True, store every trained checkpoint under results/\n",
    "GRID_BATCH_SIZES = [96, 128]\n",
    "GRID_TEMPERATURES = [0.5, 0.7, 0.9]\n",
    "GRID_WEIGHT_CONFIGS = [\n",
    "    {\"name\": \"mpnet_heavy\", \"alpha\": 0.65, \"beta_emo\": 0.08, \"beta_theme\": 0.12, \"beta_other\": 0.05, \"gamma\": 0.10},\n",
    "    {\"name\": \"balanced\", \"alpha\": 0.55, \"beta_emo\": 0.12, \"beta_theme\": 0.15, \"beta_other\": 0.08, \"gamma\": 0.10},\n",
    "    {\"name\": \"semantic_push\", \"alpha\": 0.45, \"beta_emo\": 0.18, \"beta_theme\": 0.20, \"beta_other\": 0.07, \"gamma\": 0.10},\n",
    "    {\"name\": \"structure_boost\", \"alpha\": 0.50, \"beta_emo\": 0.10, \"beta_theme\": 0.12, \"beta_other\": 0.08, \"gamma\": 0.20},\n",
    "    {\"name\": \"other_focus\", \"alpha\": 0.50, \"beta_emo\": 0.10, \"beta_theme\": 0.12, \"beta_other\": 0.18, \"gamma\": 0.10},\n",
    "]\n",
    "GRID_POS_TOPK = [POS_TOPK]\n",
    "GRID_EASY_THRESH = [EASY_THRESHOLD]\n",
    "GRID_EASY_PERCENTILES = [EASY_NEG_PERCENTILE]\n",
    "GRID_SAMPLES_PER_EPOCH = [4000]\n",
    "MAX_CONFIGS = 30\n",
    "\n",
    "grid_configs = []\n",
    "for bs, temp, weights, pos_k, easy_thr, easy_pct, spe in product(\n",
    "    GRID_BATCH_SIZES,\n",
    "    GRID_TEMPERATURES,\n",
    "    GRID_WEIGHT_CONFIGS,\n",
    "    GRID_POS_TOPK,\n",
    "    GRID_EASY_THRESH,\n",
    "    GRID_EASY_PERCENTILES,\n",
    "    GRID_SAMPLES_PER_EPOCH,\n",
    "):\n",
    "    cfg = {\n",
    "        \"label\": f\"{weights['name']}_bs{bs}_t{temp:.2f}_spe{spe}\",\n",
    "        \"batch_size\": bs,\n",
    "        \"temperature\": temp,\n",
    "        \"weights\": weights,\n",
    "        \"pos_topk\": pos_k,\n",
    "        \"hard_topk\": HARD_TOPK,\n",
    "        \"easy_threshold\": easy_thr,\n",
    "        \"easy_percentile\": easy_pct,\n",
    "        \"samples_per_epoch\": spe,\n",
    "        \"lr\": LR,\n",
    "        \"epochs\": min(EPOCHS, 250),\n",
    "        \"patience\": min(EARLY_STOP_PATIENCE, 20),\n",
    "        \"delta\": EARLY_STOP_DELTA,\n",
    "        \"warmup_epochs\": min(WARMUP_EPOCHS, 5),\n",
    "        \"min_lr\": MIN_LR,\n",
    "        \"use_cosine_schedule\": USE_COSINE_SCHEDULE,\n",
    "        \"moving_avg_window\": MOVING_AVG_WINDOW,\n",
    "        \"seed\": 1337,\n",
    "    }\n",
    "    grid_configs.append(cfg)\n",
    "    if len(grid_configs) >= MAX_CONFIGS:\n",
    "        break\n",
    "\n",
    "if not RUN_GRID_SEARCH:\n",
    "    print(f\"Grid search configured for {len(grid_configs)} runs. Set RUN_GRID_SEARCH = True to execute.\")\n",
    "else:\n",
    "    results = []\n",
    "    best_result = None\n",
    "    result_dir = Path(\"results\")\n",
    "    result_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for idx, cfg in enumerate(grid_configs, start=1):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Config {idx}/{len(grid_configs)} :: {cfg['label']}\")\n",
    "        weights = cfg[\"weights\"]\n",
    "        cos_matrix = combine_cosine_matrix(weights)\n",
    "        rng = np.random.default_rng(cfg.get(\"seed\", 0) + idx)\n",
    "        pos_pairs, hard_pairs, neg_pairs = build_pairs_from_matrix(\n",
    "            cos_matrix,\n",
    "            pos_topk=cfg[\"pos_topk\"],\n",
    "            hard_topk=cfg[\"hard_topk\"],\n",
    "            easy_threshold=cfg[\"easy_threshold\"],\n",
    "            easy_percentile=cfg[\"easy_percentile\"],\n",
    "            easy_samples=EASY_NEG_SAMPLES,\n",
    "            rng=rng,\n",
    "        )\n",
    "        _, loader_local = make_loader_for_config(\n",
    "            pos_pairs,\n",
    "            neg_pairs,\n",
    "            hard_pairs,\n",
    "            batch_size=cfg[\"batch_size\"],\n",
    "            samples_per_epoch=cfg[\"samples_per_epoch\"],\n",
    "        )\n",
    "        train_out = train_single_config(\n",
    "            loader_local,\n",
    "            temperature=cfg[\"temperature\"],\n",
    "            lr=cfg[\"lr\"],\n",
    "            epochs=cfg[\"epochs\"],\n",
    "            patience=cfg[\"patience\"],\n",
    "            delta=cfg[\"delta\"],\n",
    "            warmup_epochs=cfg[\"warmup_epochs\"],\n",
    "            min_lr=cfg[\"min_lr\"],\n",
    "            use_cosine_schedule=cfg[\"use_cosine_schedule\"],\n",
    "            moving_avg_window=cfg[\"moving_avg_window\"],\n",
    "            seed=cfg.get(\"seed\"),\n",
    "        )\n",
    "        triplet_acc = evaluate_on_triplets(train_out[\"model\"])\n",
    "        result_row = {\n",
    "            \"label\": cfg[\"label\"],\n",
    "            \"batch_size\": cfg[\"batch_size\"],\n",
    "            \"temperature\": cfg[\"temperature\"],\n",
    "            \"weights\": weights,\n",
    "            \"triplet_acc\": triplet_acc,\n",
    "            \"best_loss\": train_out[\"best_loss\"],\n",
    "            \"epochs_trained\": train_out[\"epochs_trained\"],\n",
    "            \"train_time_sec\": train_out[\"train_time\"],\n",
    "            \"pos_pairs\": len(pos_pairs),\n",
    "            \"easy_pairs\": len(neg_pairs),\n",
    "            \"hard_pairs\": len(hard_pairs),\n",
    "        }\n",
    "        results.append(result_row)\n",
    "        checkpoint_name = f\"grid_{cfg['label']}.pt\"\n",
    "        checkpoint_path = result_dir / checkpoint_name\n",
    "        if SAVE_ALL_MODELS:\n",
    "            torch.save(train_out[\"model\"].state_dict(), checkpoint_path)\n",
    "        print(\n",
    "            f\"{cfg['label']}  acc {triplet_acc*100:.2f}% | best loss {train_out['best_loss']:.4f} | \"\n",
    "            f\"pairs (pos/hard/easy) {len(pos_pairs)}/{len(hard_pairs)}/{len(neg_pairs)} | \"\n",
    "            f\"checkpoint {checkpoint_name if SAVE_ALL_MODELS else 'n/a'}\"\n",
    "        )\n",
    "        if best_result is None or result_row[\"triplet_acc\"] > best_result[\"triplet_acc\"]:\n",
    "            best_state = {k: v.cpu() for k, v in train_out[\"model\"].state_dict().items()}\n",
    "            best_result = {**result_row, \"state_dict\": best_state}\n",
    "    results_sorted = sorted(results, key=lambda r: r[\"triplet_acc\"], reverse=True)\n",
    "    summary_path = result_dir / \"grid_search_results.json\"\n",
    "    with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results_sorted, f, indent=2)\n",
    "    print(f\"\\nSaved summary to {summary_path}\")\n",
    "    if best_result:\n",
    "        best_path = result_dir / f\"grid_best_{best_result['label']}.pt\"\n",
    "        torch.save(best_result[\"state_dict\"], best_path)\n",
    "        print(\n",
    "            f\"Best config: {best_result['label']} | acc {best_result['triplet_acc']*100:.2f}% | checkpoint  {best_path}\",\n",
    "        )\n",
    "    print(\"Top-5 configs:\")\n",
    "    for row in results_sorted[:5]:\n",
    "        print(\n",
    "            f\"  {row['label']}: acc {row['triplet_acc']*100:.2f}% | loss {row['best_loss']:.4f} | epochs {row['epochs_trained']}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNet baseline accuracy: 67.39% (31/46 comparisons)\n"
     ]
    }
   ],
   "source": [
    "# MPNet-only baseline accuracy check\n",
    "if \"human_triplets\" not in globals():\n",
    "    raise RuntimeError(\"human_triplets not available. Re-run Cells 3-6 before computing the baseline.\")\n",
    "poem_vectors = poem_in[\"mpnet\"]\n",
    "song_vectors = song_in[\"mpnet\"]\n",
    "correct = 0\n",
    "for poem_idx, song1_idx, song2_idx, label in human_triplets:\n",
    "    sim1 = float(np.dot(poem_vectors[poem_idx], song_vectors[song1_idx]))\n",
    "    sim2 = float(np.dot(poem_vectors[poem_idx], song_vectors[song2_idx]))\n",
    "    pred = 1 if sim1 > sim2 else 2\n",
    "    if pred == label:\n",
    "        correct += 1\n",
    "mpnet_accuracy = correct / len(human_triplets) if human_triplets else float(\"nan\")\n",
    "print(f\"MPNet baseline accuracy: {mpnet_accuracy*100:.2f}% ({correct}/{len(human_triplets)} comparisons)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhkjxY/YsXdDuc4G7l52t2",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
