{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/xinyuezhang-shirley/cs229FinalProject/blob/main/CS229_ProjectionLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvcom4jd77aj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 128                \n",
    "EPOCHS = 500              # maximum epochs (early stop may cut short)\n",
    "LR = 2e-3                 # base learning rate (after warmup)\n",
    "TEMP = 0.7                # InfoNCE temperature\n",
    "SAMPLES_PER_EPOCH = 5000   # samples per epoch  \n",
    "\n",
    "# Learning rate schedule / early stopping\n",
    "WARMUP_EPOCHS = 5         # linear warmup epochs\n",
    "MIN_LR = 1e-3             # final minimum LR for cosine schedule\n",
    "USE_COSINE_SCHEDULE = True\n",
    "EARLY_STOP_PATIENCE = 25  # epochs (post-warmup) with no sufficient improvement\n",
    "EARLY_STOP_DELTA = 0.002  # required loss decrease to reset patience\n",
    "MOVING_AVG_WINDOW = 10    # for smoothed loss\n",
    "\n",
    "# Modality weights (kept same)\n",
    "ALPHA = 0.6       # MPNet branch\n",
    "BETA_EMO = 0.1    # emotion semantics\n",
    "BETA_THEME = 0.15 # theme semantics\n",
    "BETA_OTHER = 0.1  # other semantics (sentiment, subjectivity, concreteness, energy, narrative, imagery)\n",
    "GAMMA = 0.15      # structural/lexical branch\n",
    "\n",
    "# Unsupervised pair construction hyperparameters\n",
    "POS_TOPK = 5        # positives per poem from similarity\n",
    "HARD_TOPK = 10       # hard negatives per poem (near misses)\n",
    "EASY_THRESHOLD = 0.25  # cosine threshold for easy negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcT0UQyQn9qU",
    "outputId": "04956265-cf14-42f1-bd85-05563014d01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poems: 3413 items\n",
      "Songs: 2995 items\n",
      "poem_vecs: (3413, 768), song_vecs: (2995, 768)\n",
      "poem_feats: (3413, 6), song_feats: (2995, 6)\n",
      "poem_sem (emo/theme/other): (3413, 9), (3413, 10), (3413, 17)\n",
      "song_sem (emo/theme/other): (2995, 9), (2995, 10), (2995, 17)\n"
     ]
    }
   ],
   "source": [
    "# MPNet embeddings (raw, not yet filtered)\n",
    "poem_vecs = np.load(\"data/processed/mpnet_embeddings_poems.npy\")\n",
    "song_vecs = np.load(\"data/processed/mpnet_embeddings_songs.npy\")\n",
    "\n",
    "# Load all features from full_features.npz\n",
    "full = np.load(\"data/processed/full_features.npz\", allow_pickle=True)\n",
    "\n",
    "# Structural + lexical features (concatenated)\n",
    "poem_struct = full[\"poem_struct\"]  # (3413, 3)\n",
    "poem_lexical = full[\"poem_lexical\"]  # (3413, 3)\n",
    "poem_feats = np.concatenate([poem_struct, poem_lexical], axis=1)  # (3413, 6)\n",
    "\n",
    "song_struct = full[\"song_struct\"]  # (2995, 4)\n",
    "song_lexical = full[\"song_lexical\"]  # (2995, 3)\n",
    "# For songs, only use first 3 structural features to match poems (exclude WPM)\n",
    "song_feats = np.concatenate([song_struct[:, :3], song_lexical], axis=1)  # (2995, 6)\n",
    "\n",
    "# Semantic features\n",
    "poem_sem_all = full[\"poem_semantic\"]  # (3413, 36)\n",
    "song_sem_all = full[\"song_semantic\"]  # (2995, 36)\n",
    "\n",
    "# Split semantic features by groups\n",
    "# emotions(9): 0-9, themes(10): 9-19, other(17): 19-36\n",
    "poem_sem_emo   = poem_sem_all[:, 0:9]\n",
    "poem_sem_theme = poem_sem_all[:, 9:19]\n",
    "poem_sem_other = poem_sem_all[:, 19:36]\n",
    "song_sem_emo   = song_sem_all[:, 0:9]\n",
    "song_sem_theme = song_sem_all[:, 9:19]\n",
    "song_sem_other = song_sem_all[:, 19:36]\n",
    "\n",
    "# Align song embeddings to match cleaned features\n",
    "idx_map = full[\"song_source_indexes\"]  # (2995,) maps cleaned songs -> raw embedding indices\n",
    "song_vecs = song_vecs[idx_map]  # reorder raw embeddings to match cleaned data\n",
    "\n",
    "print(f\"Poems: {poem_vecs.shape[0]} items\")\n",
    "print(f\"Songs: {song_vecs.shape[0]} items\")\n",
    "print(f\"poem_vecs: {poem_vecs.shape}, song_vecs: {song_vecs.shape}\")\n",
    "print(f\"poem_feats: {poem_feats.shape}, song_feats: {song_feats.shape}\")\n",
    "print(f\"poem_sem (emo/theme/other): {poem_sem_emo.shape}, {poem_sem_theme.shape}, {poem_sem_other.shape}\")\n",
    "print(f\"song_sem (emo/theme/other): {song_sem_emo.shape}, {song_sem_theme.shape}, {song_sem_other.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poem branches: (3413, 768) (3413, 9) (3413, 10) (3413, 17) (3413, 6)\n",
      "song  branches: (2995, 768) (2995, 9) (2995, 10) (2995, 17) (2995, 6)\n",
      "Loading precomputed cosine matrix from data/processed/mpnet_pairwise_cosine_matrix.npy...\n",
      "Loaded matrix shape: torch.Size([3413, 2995])\n",
      "Building pairs with POS_TOPK=5, HARD_TOPK=10, EASY_THRESHOLD=0.25...\n",
      "Built pairs -> pos: 17065 hard: 34130 easy: 17065\n"
     ]
    }
   ],
   "source": [
    "# Normalize MPNet embeddings per row to balance scales\n",
    "poem_vecs = poem_vecs / (np.linalg.norm(poem_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "song_vecs = song_vecs / (np.linalg.norm(song_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Build branch inputs\n",
    "poem_in = {\n",
    "    \"mpnet\": poem_vecs,\n",
    "    \"sem_emo\":   poem_sem_emo,\n",
    "    \"sem_theme\": poem_sem_theme,\n",
    "    \"sem_other\": poem_sem_other,\n",
    "    \"feat\":  poem_feats,\n",
    "}\n",
    "song_in = {\n",
    "    \"mpnet\": song_vecs,\n",
    "    \"sem_emo\":   song_sem_emo,\n",
    "    \"sem_theme\": song_sem_theme,\n",
    "    \"sem_other\": song_sem_other,\n",
    "    \"feat\":  song_feats,\n",
    "}\n",
    "\n",
    "print(\"poem branches:\", poem_in[\"mpnet\"].shape, poem_in[\"sem_emo\"].shape, poem_in[\"sem_theme\"].shape, poem_in[\"sem_other\"].shape, poem_in[\"feat\"].shape)\n",
    "print(\"song  branches:\", song_in[\"mpnet\"].shape, song_in[\"sem_emo\"].shape, song_in[\"sem_theme\"].shape, song_in[\"sem_other\"].shape, song_in[\"feat\"].shape)\n",
    "\n",
    "# Compute or load precomputed pairwise cosine similarity matrix\n",
    "import torch\n",
    "import os\n",
    "\n",
    "cosine_matrix_path = \"data/processed/mpnet_pairwise_cosine_matrix.npy\"\n",
    "\n",
    "if os.path.exists(cosine_matrix_path):\n",
    "    print(f\"Loading precomputed cosine matrix from {cosine_matrix_path}...\")\n",
    "    cos_matrix_t = torch.from_numpy(np.load(cosine_matrix_path)).to(DEVICE)\n",
    "    print(f\"Loaded matrix shape: {cos_matrix_t.shape}\")\n",
    "else:\n",
    "    print(\"Computing pairwise cosine similarity matrix on GPU...\")\n",
    "    # Move MPNet branches to GPU tensors\n",
    "    p_mp = torch.from_numpy(poem_in[\"mpnet\"]).to(torch.float32).to(DEVICE)\n",
    "    s_mp = torch.from_numpy(song_in[\"mpnet\"]).to(torch.float32).to(DEVICE)\n",
    "    \n",
    "    # Compute cosine similarity matrix via matmul on GPU (all poem-song pairs)\n",
    "    cos_matrix_t = torch.matmul(p_mp, s_mp.T)  # [P, S]\n",
    "    \n",
    "    # Save to cache\n",
    "    np.save(cosine_matrix_path, cos_matrix_t.cpu().numpy())\n",
    "    print(f\"Saved cosine matrix to {cosine_matrix_path}\")\n",
    "\n",
    "# Build pos/hard/neg pairs from current hyperparameters (always recompute based on thresholds)\n",
    "print(f\"Building pairs with POS_TOPK={POS_TOPK}, HARD_TOPK={HARD_TOPK}, EASY_THRESHOLD={EASY_THRESHOLD}...\")\n",
    "P, S = cos_matrix_t.shape\n",
    "pos_pairs = []\n",
    "hard_pairs = []\n",
    "neg_pairs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # For each poem, get top (POS_TOPK + HARD_TOPK) indices\n",
    "    topk_vals, topk_idxs = torch.topk(cos_matrix_t, k=min(S, POS_TOPK + HARD_TOPK), dim=1, largest=True, sorted=True)\n",
    "\n",
    "    # Build pos and hard lists\n",
    "    for i in range(P):\n",
    "        # positives\n",
    "        for j in topk_idxs[i, :POS_TOPK].tolist():\n",
    "            pos_pairs.append((int(i), int(j)))\n",
    "        # hard negatives (near misses)\n",
    "        for j in topk_idxs[i, POS_TOPK:POS_TOPK+HARD_TOPK].tolist():\n",
    "            hard_pairs.append((int(i), int(j)))\n",
    "\n",
    "    # Easy negatives: cosine below threshold; sample a few per poem\n",
    "    easy_mask = cos_matrix_t <= EASY_THRESHOLD\n",
    "    for i in range(P):\n",
    "        low_idxs = torch.nonzero(easy_mask[i], as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "        if low_idxs.size > 0:\n",
    "            sample_ct = min(5, low_idxs.size)\n",
    "            choice = np.random.choice(low_idxs, size=sample_ct, replace=False)\n",
    "            for j in choice:\n",
    "                neg_pairs.append((int(i), int(j)))\n",
    "\n",
    "print(f\"Built pairs -> pos: {len(pos_pairs)} hard: {len(hard_pairs)} easy: {len(neg_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5000 samples/epoch, loader batches: 40\n"
     ]
    }
   ],
   "source": [
    "# Pre-build GPU tensors so batching is instant\n",
    "poem_gpu = {}\n",
    "song_gpu = {}\n",
    "\n",
    "for k in poem_in:\n",
    "    poem_gpu[k] = torch.from_numpy(poem_in[k]).to(torch.float32).to(DEVICE)\n",
    "    song_gpu[k] = torch.from_numpy(song_in[k]).to(torch.float32).to(DEVICE)\n",
    "\n",
    "# Build dataset and loader\n",
    "dataset = PairDataset(pos_pairs, neg_pairs, hard_pairs, size=SAMPLES_PER_EPOCH)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples/epoch, loader batches: {len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_loss(poem_emb, song_emb, temperature=TEMP):\n",
    "    \"\"\"\n",
    "    InfoNCE / contrastive loss for a batch of poem/song embedding pairs.\n",
    "    \n",
    "    Args:\n",
    "        poem_emb: [B, D] poem embeddings\n",
    "        song_emb: [B, D] song embeddings\n",
    "        temperature: scaling for logits\n",
    "    \n",
    "    Returns:\n",
    "        Scalar loss\n",
    "    \"\"\"\n",
    "    # Normalize both\n",
    "    poem_emb = F.normalize(poem_emb, dim=1)\n",
    "    song_emb = F.normalize(song_emb, dim=1)\n",
    "    \n",
    "    B = poem_emb.shape[0]\n",
    "    \n",
    "    # Compute all-pairs similarity: [B, B]\n",
    "    logits = torch.matmul(poem_emb, song_emb.T) / temperature\n",
    "    \n",
    "    # Positives on diagonal, negatives off-diagonal\n",
    "    labels = torch.arange(B, device=poem_emb.device)\n",
    "    \n",
    "    # Symmetric loss: poem->song + song->poem\n",
    "    loss_p2s = F.cross_entropy(logits, labels)\n",
    "    loss_s2p = F.cross_entropy(logits.T, labels)\n",
    "    \n",
    "    return (loss_p2s + loss_s2p) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 10/500 | Loss: 4.2158 | Smoothed: 4.2316 | LR: 0.002000 | Patience: 0/25\n",
      "Epoch 10/500 | Loss: 4.2158 | Smoothed: 4.2316 | LR: 0.002000 | Patience: 0/25\n",
      "Epoch 20/500 | Loss: 4.1624 | Smoothed: 4.1694 | LR: 0.001998 | Patience: 0/25\n",
      "Epoch 20/500 | Loss: 4.1624 | Smoothed: 4.1694 | LR: 0.001998 | Patience: 0/25\n",
      "Epoch 30/500 | Loss: 4.1382 | Smoothed: 4.1505 | LR: 0.001994 | Patience: 0/25\n",
      "Epoch 30/500 | Loss: 4.1382 | Smoothed: 4.1505 | LR: 0.001994 | Patience: 0/25\n",
      "Epoch 40/500 | Loss: 4.1406 | Smoothed: 4.1475 | LR: 0.001988 | Patience: 6/25\n",
      "Epoch 40/500 | Loss: 4.1406 | Smoothed: 4.1475 | LR: 0.001988 | Patience: 6/25\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    print(\"Starting training...\")\n",
    "    model.train()\n",
    "    \n",
    "    loss_history = []\n",
    "    lr_history = []\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 25\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    delta = 0.002  # minimum improvement\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch_idx, (pidxs, sidxs) in enumerate(loader):\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # Build batch inputs for each branch\n",
    "            batch_poem = {k: poem_gpu[k][pidxs] for k in poem_gpu}\n",
    "            batch_song = {k: song_gpu[k][sidxs] for k in song_gpu}\n",
    "            \n",
    "            # Forward pass\n",
    "            poem_out = model.forward_poem(batch_poem)\n",
    "            song_out = model.forward_song(batch_song)\n",
    "            \n",
    "            # InfoNCE loss\n",
    "            loss = clip_loss(poem_out, song_out, temperature=TEMP)\n",
    "            \n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        # Epoch metrics\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        loss_history.append(avg_loss)\n",
    "        \n",
    "        # Smoothed loss for early stopping (last 5 epochs)\n",
    "        smoothed_loss = np.mean(loss_history[-5:]) if len(loss_history) >= 5 else avg_loss\n",
    "        \n",
    "        # Check improvement\n",
    "        if smoothed_loss < best_loss - delta:\n",
    "            best_loss = smoothed_loss\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Step schedulers\n",
    "        if warmup_scheduler and epoch < WARMUP_EPOCHS:\n",
    "            warmup_scheduler.step()\n",
    "        elif scheduler_main:\n",
    "            scheduler_main.step()\n",
    "        \n",
    "        current_lr = opt.param_groups[0]['lr']\n",
    "        lr_history.append(current_lr)\n",
    "        \n",
    "        # Print every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Smoothed: {smoothed_loss:.4f} | LR: {current_lr:.6f} | Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} - no improvement for {patience} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Restore best state\n",
    "    if best_state is not None:\n",
    "        print(f\"Restoring best model (smoothed loss: {best_loss:.4f})\")\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "else:\n",
    "    print(\"SKIP_TRAINING=True, loading saved model...\")\n",
    "    loss_history = []\n",
    "    lr_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training history to plot (SKIP_TRAINING=True)\n"
     ]
    }
   ],
   "source": [
    "# Plot training curves\n",
    "if len(loss_history) > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # Loss curve\n",
    "    ax1.plot(loss_history, label=\"Train Loss\", color='steelblue')\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"InfoNCE Loss\")\n",
    "    ax1.set_title(\"Training Loss Curve\")\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    ax2.plot(lr_history, label=\"Learning Rate\", color='coral')\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"LR\")\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Final loss: {loss_history[-1]:.4f}, Best smoothed loss: {best_loss:.4f}\")\n",
    "else:\n",
    "    print(\"No training history to plot (SKIP_TRAINING=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sNEKioCoDl4"
   },
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pos_pairs, neg_pairs, hard_pairs, size):\n",
    "        \"\"\"\n",
    "        Returns poem/song indices for each sample.\n",
    "        size = number of samples per epoch\n",
    "        \"\"\"\n",
    "        self.pos_pairs  = pos_pairs\n",
    "        self.neg_pairs  = neg_pairs\n",
    "        self.hard_pairs = hard_pairs\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sample random positive pair\n",
    "        i_poem, j_song = self.pos_pairs[np.random.randint(len(self.pos_pairs))]\n",
    "        \n",
    "        # Return indices only (training loop will index the actual data)\n",
    "        return i_poem, j_song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7U7AM1ToG3D"
   },
   "outputs": [],
   "source": [
    "# Branch sizes\n",
    "p_dim_mp = poem_in[\"mpnet\"].shape[1]\n",
    "p_dim_emo = poem_in[\"sem_emo\"].shape[1]\n",
    "p_dim_theme = poem_in[\"sem_theme\"].shape[1]\n",
    "p_dim_other = poem_in[\"sem_other\"].shape[1]\n",
    "p_dim_ft  = poem_in[\"feat\"].shape[1]\n",
    "s_dim_mp = song_in[\"mpnet\"].shape[1]\n",
    "s_dim_emo = song_in[\"sem_emo\"].shape[1]\n",
    "s_dim_theme = song_in[\"sem_theme\"].shape[1]\n",
    "s_dim_other = song_in[\"sem_other\"].shape[1]\n",
    "s_dim_ft  = song_in[\"feat\"].shape[1]\n",
    "proj_dim = 128\n",
    "\n",
    "class ProjectionModel(nn.Module):\n",
    "    def __init__(self, p_dims, s_dims, proj_dim):\n",
    "        super().__init__()\n",
    "        p_mp, p_emo, p_theme, p_other, p_ft = p_dims\n",
    "        s_mp, s_emo, s_theme, s_other, s_ft = s_dims\n",
    "        # poem branches\n",
    "        self.poem_mp = nn.Sequential(nn.Linear(p_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.poem_emo = nn.Sequential(nn.Linear(max(p_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_theme = nn.Sequential(nn.Linear(max(p_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_other = nn.Sequential(nn.Linear(max(p_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_ft = nn.Sequential(nn.Linear(p_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "        # song branches\n",
    "        self.song_mp = nn.Sequential(nn.Linear(s_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.song_emo = nn.Sequential(nn.Linear(max(s_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_theme = nn.Sequential(nn.Linear(max(s_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_other = nn.Sequential(nn.Linear(max(s_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_ft = nn.Sequential(nn.Linear(s_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "    def forward_poem(self, p):\n",
    "        mp = self.poem_mp(p[\"mpnet\"])\n",
    "        emo_in = p[\"sem_emo\"] if p_dim_emo>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        theme_in = p[\"sem_theme\"] if p_dim_theme>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        other_in = p[\"sem_other\"] if p_dim_other>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        emo = self.poem_emo(emo_in)\n",
    "        theme = self.poem_theme(theme_in)\n",
    "        other = self.poem_other(other_in)\n",
    "        ft  = self.poem_ft(p[\"feat\"])\n",
    "        comb = torch.cat([ALPHA*mp, BETA_EMO*emo, BETA_THEME*theme, BETA_OTHER*other, GAMMA*ft], dim=1)\n",
    "        z = self.poem_proj(comb)\n",
    "        return F.normalize(z, dim=1)\n",
    "    def forward_song(self, s):\n",
    "        mp = self.song_mp(s[\"mpnet\"])\n",
    "        emo_in = s[\"sem_emo\"] if s_dim_emo>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        theme_in = s[\"sem_theme\"] if s_dim_theme>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        other_in = s[\"sem_other\"] if s_dim_other>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        emo = self.song_emo(emo_in)\n",
    "        theme = self.song_theme(theme_in)\n",
    "        other = self.song_other(other_in)\n",
    "        ft  = self.song_ft(s[\"feat\"])\n",
    "        comb = torch.cat([ALPHA*mp, BETA_EMO*emo, BETA_THEME*theme, BETA_OTHER*other, GAMMA*ft], dim=1)\n",
    "        z = self.song_proj(comb)\n",
    "        return F.normalize(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eChWn15JoIUW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found. Will train and save to model_bs128_ep500_lr0.002_temp0.7_posK5_hardK10_a0.6_bemo0.1_bthm0.15_both0.1_g0.15.pt\n"
     ]
    }
   ],
   "source": [
    "# Build model filename from hyperparameters\n",
    "model_name = (f\"model_bs{BATCH_SIZE}_ep{EPOCHS}_lr{LR}_temp{TEMP}_\"\n",
    "             f\"posK{POS_TOPK}_hardK{HARD_TOPK}_\"\n",
    "             f\"a{ALPHA}_bemo{BETA_EMO}_bthm{BETA_THEME}_both{BETA_OTHER}_g{GAMMA}.pt\")\n",
    "\n",
    "model = ProjectionModel(\n",
    "    (p_dim_mp, p_dim_emo, p_dim_theme, p_dim_other, p_dim_ft),\n",
    "    (s_dim_mp, s_dim_emo, s_dim_theme, s_dim_other, s_dim_ft),\n",
    "    proj_dim\n",
    ").to(DEVICE)\n",
    "\n",
    "# Check if model already exists\n",
    "if os.path.exists(model_name):\n",
    "    print(f\"Loading existing model from {model_name}...\")\n",
    "    model.load_state_dict(torch.load(model_name, map_location=DEVICE))\n",
    "    print(\"Model loaded. Skipping training.\")\n",
    "    SKIP_TRAINING = True\n",
    "else:\n",
    "    print(f\"No existing model found. Will train and save to {model_name}\")\n",
    "    SKIP_TRAINING = False\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Set up schedulers (created even if may not be used to keep code simple)\n",
    "if USE_COSINE_SCHEDULE and not SKIP_TRAINING:\n",
    "    # Warmup: scale LR from (1/WARMUP_EPOCHS)*LR to LR\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < WARMUP_EPOCHS:\n",
    "            return (epoch + 1) / WARMUP_EPOCHS\n",
    "        return 1.0\n",
    "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "    # Cosine anneal after warmup\n",
    "    scheduler_main = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=MIN_LR)\n",
    "else:\n",
    "    warmup_scheduler = None\n",
    "    scheduler_main = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uX3hOUhjoMKl",
    "outputId": "1420d5bd-f37b-4126-9336-836833744694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_bs128_ep500_lr0.002_temp0.7_posK5_hardK10_a0.6_bemo0.1_bthm0.15_both0.1_g0.15.pt\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "    print(f\"Model saved to {model_name}\")\n",
    "else:\n",
    "    print(\"Model already loaded; no new save needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate unsupervised model on all human triplets\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = len(human_triplets)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p_idx, s1_idx, s2_idx, label in human_triplets:\n",
    "        # Get embeddings for poem and both songs\n",
    "        p_batch = {\n",
    "            \"mpnet\": poem_gpu[\"mpnet\"][p_idx:p_idx+1],\n",
    "            \"sem_emo\": poem_gpu[\"sem_emo\"][p_idx:p_idx+1],\n",
    "            \"sem_theme\": poem_gpu[\"sem_theme\"][p_idx:p_idx+1],\n",
    "            \"sem_other\": poem_gpu[\"sem_other\"][p_idx:p_idx+1],\n",
    "            \"feat\": poem_gpu[\"feat\"][p_idx:p_idx+1],\n",
    "        }\n",
    "        s1_batch = {\n",
    "            \"mpnet\": song_gpu[\"mpnet\"][s1_idx:s1_idx+1],\n",
    "            \"sem_emo\": song_gpu[\"sem_emo\"][s1_idx:s1_idx+1],\n",
    "            \"sem_theme\": song_gpu[\"sem_theme\"][s1_idx:s1_idx+1],\n",
    "            \"sem_other\": song_gpu[\"sem_other\"][s1_idx:s1_idx+1],\n",
    "            \"feat\": song_gpu[\"feat\"][s1_idx:s1_idx+1],\n",
    "        }\n",
    "        s2_batch = {\n",
    "            \"mpnet\": song_gpu[\"mpnet\"][s2_idx:s2_idx+1],\n",
    "            \"sem_emo\": song_gpu[\"sem_emo\"][s2_idx:s2_idx+1],\n",
    "            \"sem_theme\": song_gpu[\"sem_theme\"][s2_idx:s2_idx+1],\n",
    "            \"sem_other\": song_gpu[\"sem_other\"][s2_idx:s2_idx+1],\n",
    "            \"feat\": song_gpu[\"feat\"][s2_idx:s2_idx+1],\n",
    "        }\n",
    "        \n",
    "        # Forward pass\n",
    "        p_z = model.forward_poem(p_batch)\n",
    "        s1_z = model.forward_song(s1_batch)\n",
    "        s2_z = model.forward_song(s2_batch)\n",
    "        \n",
    "        # Compute cosine similarities\n",
    "        sim1 = (p_z * s1_z).sum().item()\n",
    "        sim2 = (p_z * s2_z).sum().item()\n",
    "        \n",
    "        # Predict which song is closer (1 or 2)\n",
    "        pred = 1 if sim1 > sim2 else 2\n",
    "        \n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Unsupervised Model Evaluation on Human Triplets\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total triplets: {total}\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Test raw MPNet performance (no training)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE: Raw MPNet Performance (Before Training)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mpnet_correct = 0\n",
    "with torch.no_grad():\n",
    "    for p_idx, s1_idx, s2_idx, label in human_triplets:\n",
    "        # Raw MPNet cosine similarity (normalized embeddings)\n",
    "        p_mpnet = poem_gpu[\"mpnet\"][p_idx:p_idx+1]\n",
    "        s1_mpnet = song_gpu[\"mpnet\"][s1_idx:s1_idx+1]\n",
    "        s2_mpnet = song_gpu[\"mpnet\"][s2_idx:s2_idx+1]\n",
    "        \n",
    "        sim1 = (p_mpnet * s1_mpnet).sum().item()\n",
    "        sim2 = (p_mpnet * s2_mpnet).sum().item()\n",
    "        \n",
    "        pred = 1 if sim1 > sim2 else 2\n",
    "        if pred == label:\n",
    "            mpnet_correct += 1\n",
    "\n",
    "mpnet_acc = mpnet_correct / len(human_triplets)\n",
    "print(f\"Raw MPNet Accuracy: {mpnet_acc*100:.2f}% ({mpnet_correct}/{len(human_triplets)})\")\n",
    "print(f\"Your Model Accuracy: 43.48% (20/{len(human_triplets)})\")\n",
    "print(f\"\\nPerformance Loss: {(mpnet_acc - 0.4348)*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label encoding and predictions for first few examples\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEBUG: First 5 triplet predictions (check for off-by-one)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (p_idx, s1_idx, s2_idx, label) in enumerate(human_triplets[:5]):\n",
    "        # Raw MPNet\n",
    "        p_mpnet = poem_gpu[\"mpnet\"][p_idx:p_idx+1]\n",
    "        s1_mpnet = song_gpu[\"mpnet\"][s1_idx:s1_idx+1]\n",
    "        s2_mpnet = song_gpu[\"mpnet\"][s2_idx:s2_idx+1]\n",
    "        \n",
    "        mpnet_sim1 = (p_mpnet * s1_mpnet).sum().item()\n",
    "        mpnet_sim2 = (p_mpnet * s2_mpnet).sum().item()\n",
    "        mpnet_pred = 1 if mpnet_sim1 > mpnet_sim2 else 2\n",
    "        \n",
    "        # Model\n",
    "        p_batch = {\"mpnet\": poem_gpu[\"mpnet\"][p_idx:p_idx+1],\n",
    "                   \"sem_emo\": poem_gpu[\"sem_emo\"][p_idx:p_idx+1],\n",
    "                   \"sem_theme\": poem_gpu[\"sem_theme\"][p_idx:p_idx+1],\n",
    "                   \"sem_other\": poem_gpu[\"sem_other\"][p_idx:p_idx+1],\n",
    "                   \"feat\": poem_gpu[\"feat\"][p_idx:p_idx+1]}\n",
    "        s1_batch = {\"mpnet\": song_gpu[\"mpnet\"][s1_idx:s1_idx+1],\n",
    "                    \"sem_emo\": song_gpu[\"sem_emo\"][s1_idx:s1_idx+1],\n",
    "                    \"sem_theme\": song_gpu[\"sem_theme\"][s1_idx:s1_idx+1],\n",
    "                    \"sem_other\": song_gpu[\"sem_other\"][s1_idx:s1_idx+1],\n",
    "                    \"feat\": song_gpu[\"feat\"][s1_idx:s1_idx+1]}\n",
    "        s2_batch = {\"mpnet\": song_gpu[\"mpnet\"][s2_idx:s2_idx+1],\n",
    "                    \"sem_emo\": song_gpu[\"sem_emo\"][s2_idx:s2_idx+1],\n",
    "                    \"sem_theme\": song_gpu[\"sem_theme\"][s2_idx:s2_idx+1],\n",
    "                    \"sem_other\": song_gpu[\"sem_other\"][s2_idx:s2_idx+1],\n",
    "                    \"feat\": song_gpu[\"feat\"][s2_idx:s2_idx+1]}\n",
    "        \n",
    "        p_z = model.forward_poem(p_batch)\n",
    "        s1_z = model.forward_song(s1_batch)\n",
    "        s2_z = model.forward_song(s2_batch)\n",
    "        \n",
    "        model_sim1 = (p_z * s1_z).sum().item()\n",
    "        model_sim2 = (p_z * s2_z).sum().item()\n",
    "        model_pred = 1 if model_sim1 > model_sim2 else 2\n",
    "        \n",
    "        print(f\"\\nTriplet {idx}: poem={p_idx}, song1={s1_idx}, song2={s2_idx}\")\n",
    "        print(f\"  Label says: Song {label} is closer\")\n",
    "        print(f\"  MPNet: sim1={mpnet_sim1:.3f}, sim2={mpnet_sim2:.3f} → pred={mpnet_pred} {'✓' if mpnet_pred==label else '✗'}\")\n",
    "        print(f\"  Model: sim1={model_sim1:.3f}, sim2={model_sim2:.3f} → pred={model_pred} {'✓' if model_pred==label else '✗'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"If MPNet is mostly ✓ but Model is mostly ✗, training degraded performance\")\n",
    "print(\"If both are ✗, check if labels are backwards (flip 1↔2)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhkjxY/YsXdDuc4G7l52t2",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
