{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/xinyuezhang-shirley/cs229FinalProject/blob/main/CS229_ProjectionLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvcom4jd77aj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 128                \n",
    "EPOCHS = 500              # maximum epochs (early stop may cut short)\n",
    "LR = 2e-3                 # base learning rate (after warmup)\n",
    "TEMP = 0.7                # InfoNCE temperature\n",
    "SAMPLES_PER_EPOCH = 2500   # samples per epoch  \n",
    "\n",
    "# Learning rate schedule / early stopping\n",
    "WARMUP_EPOCHS = 5         # linear warmup epochs\n",
    "MIN_LR = 1e-3             # final minimum LR for cosine schedule\n",
    "USE_COSINE_SCHEDULE = True\n",
    "EARLY_STOP_PATIENCE = 25  # epochs (post-warmup) with no sufficient improvement\n",
    "EARLY_STOP_DELTA = 0.002  # required loss decrease to reset patience\n",
    "MOVING_AVG_WINDOW = 10    # for smoothed loss\n",
    "\n",
    "# Modality weights (kept same)\n",
    "ALPHA = 0.6       # MPNet branch\n",
    "BETA_EMO = 0.1    # emotion semantics\n",
    "BETA_THEME = 0.15 # theme semantics\n",
    "BETA_OTHER = 0.1  # other semantics (sentiment, subjectivity, concreteness, energy, narrative, imagery)\n",
    "GAMMA = 0.15      # structural/lexical branch\n",
    "\n",
    "# Unsupervised pair construction hyperparameters\n",
    "POS_TOPK = 5        # positives per poem from similarity\n",
    "HARD_TOPK = 0       # hard negatives per poem (near misses)\n",
    "EASY_THRESHOLD = 0.25  # cosine threshold for easy negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcT0UQyQn9qU",
    "outputId": "04956265-cf14-42f1-bd85-05563014d01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poems: 3413 items\n",
      "Songs: 2995 items\n",
      "poem_vecs: (3413, 768), song_vecs: (2995, 768)\n",
      "poem_feats: (3413, 6), song_feats: (2995, 6)\n",
      "poem_sem (emo/theme/other): (3413, 9), (3413, 10), (3413, 17)\n",
      "song_sem (emo/theme/other): (2995, 9), (2995, 10), (2995, 17)\n"
     ]
    }
   ],
   "source": [
    "# MPNet embeddings (raw, not yet filtered)\n",
    "poem_vecs = np.load(\"data/processed/mpnet_embeddings_poems.npy\")\n",
    "song_vecs = np.load(\"data/processed/mpnet_embeddings_songs.npy\")\n",
    "\n",
    "# Load all features from full_features.npz\n",
    "full = np.load(\"data/processed/full_features.npz\", allow_pickle=True)\n",
    "\n",
    "# Structural + lexical features (concatenated)\n",
    "poem_struct = full[\"poem_struct\"]  # (3413, 3)\n",
    "poem_lexical = full[\"poem_lexical\"]  # (3413, 3)\n",
    "poem_feats = np.concatenate([poem_struct, poem_lexical], axis=1)  # (3413, 6)\n",
    "\n",
    "song_struct = full[\"song_struct\"]  # (2995, 4)\n",
    "song_lexical = full[\"song_lexical\"]  # (2995, 3)\n",
    "# For songs, only use first 3 structural features to match poems (exclude WPM)\n",
    "song_feats = np.concatenate([song_struct[:, :3], song_lexical], axis=1)  # (2995, 6)\n",
    "\n",
    "# Semantic features\n",
    "poem_sem_all = full[\"poem_semantic\"]  # (3413, 36)\n",
    "song_sem_all = full[\"song_semantic\"]  # (2995, 36)\n",
    "\n",
    "# Split semantic features by groups\n",
    "# emotions(9): 0-9, themes(10): 9-19, other(17): 19-36\n",
    "poem_sem_emo   = poem_sem_all[:, 0:9]\n",
    "poem_sem_theme = poem_sem_all[:, 9:19]\n",
    "poem_sem_other = poem_sem_all[:, 19:36]\n",
    "song_sem_emo   = song_sem_all[:, 0:9]\n",
    "song_sem_theme = song_sem_all[:, 9:19]\n",
    "song_sem_other = song_sem_all[:, 19:36]\n",
    "\n",
    "# Align song embeddings to match cleaned features\n",
    "idx_map = full[\"song_source_indexes\"]  # (2995,) maps cleaned songs -> raw embedding indices\n",
    "song_vecs = song_vecs[idx_map]  # reorder raw embeddings to match cleaned data\n",
    "\n",
    "print(f\"Poems: {poem_vecs.shape[0]} items\")\n",
    "print(f\"Songs: {song_vecs.shape[0]} items\")\n",
    "print(f\"poem_vecs: {poem_vecs.shape}, song_vecs: {song_vecs.shape}\")\n",
    "print(f\"poem_feats: {poem_feats.shape}, song_feats: {song_feats.shape}\")\n",
    "print(f\"poem_sem (emo/theme/other): {poem_sem_emo.shape}, {poem_sem_theme.shape}, {poem_sem_other.shape}\")\n",
    "print(f\"song_sem (emo/theme/other): {song_sem_emo.shape}, {song_sem_theme.shape}, {song_sem_other.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poem branches: (3413, 768) (3413, 9) (3413, 10) (3413, 17) (3413, 6)\n",
      "song  branches: (2995, 768) (2995, 9) (2995, 10) (2995, 17) (2995, 6)\n",
      "Loading precomputed cosine matrix from data/processed/mpnet_pairwise_cosine_matrix.npy...\n",
      "Loaded matrix shape: torch.Size([3413, 2995])\n",
      "Building pairs with POS_TOPK=5, HARD_TOPK=10, EASY_THRESHOLD=0.25...\n",
      "Built pairs -> pos: 17065 hard: 34130 easy: 17065\n"
     ]
    }
   ],
   "source": [
    "# Normalize MPNet embeddings per row to balance scales\n",
    "poem_vecs = poem_vecs / (np.linalg.norm(poem_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "song_vecs = song_vecs / (np.linalg.norm(song_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Build branch inputs\n",
    "poem_in = {\n",
    "    \"mpnet\": poem_vecs.astype(np.float32),\n",
    "    \"sem_emo\":   poem_sem_emo.astype(np.float32),\n",
    "    \"sem_theme\": poem_sem_theme.astype(np.float32),\n",
    "    \"sem_other\": poem_sem_other.astype(np.float32),\n",
    "    \"feat\":  poem_feats.astype(np.float32),\n",
    "}\n",
    "song_in = {\n",
    "    \"mpnet\": song_vecs.astype(np.float32),\n",
    "    \"sem_emo\":   song_sem_emo.astype(np.float32),\n",
    "    \"sem_theme\": song_sem_theme.astype(np.float32),\n",
    "    \"sem_other\": song_sem_other.astype(np.float32),\n",
    "    \"feat\":  song_feats.astype(np.float32),\n",
    "}\n",
    "\n",
    "def _row_norm(x):\n",
    "    return x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "print(\"poem branches:\", poem_in[\"mpnet\"].shape, poem_in[\"sem_emo\"].shape, poem_in[\"sem_theme\"].shape, poem_in[\"sem_other\"].shape, poem_in[\"feat\"].shape)\n",
    "print(\"song  branches:\", song_in[\"mpnet\"].shape, song_in[\"sem_emo\"].shape, song_in[\"sem_theme\"].shape, song_in[\"sem_other\"].shape, song_in[\"feat\"].shape)\n",
    "\n",
    "# Compute or load precomputed pairwise cosine matrices per modality and combine with weights\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "cosine_cache_dir = Path(\"data/processed/cosine_mats\")\n",
    "cosine_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_cosine_matrix(p_feat, s_feat, name):\n",
    "    cache_path = cosine_cache_dir / f\"cosine_{name}.npy\"\n",
    "    if cache_path.exists():\n",
    "        print(f\"Loading {name} cosine matrix from {cache_path}...\")\n",
    "        return torch.from_numpy(np.load(cache_path)).to(DEVICE)\n",
    "    print(f\"Computing {name} cosine matrix on GPU...\")\n",
    "    p_norm = torch.from_numpy(_row_norm(p_feat)).to(torch.float32).to(DEVICE)\n",
    "    s_norm = torch.from_numpy(_row_norm(s_feat)).to(torch.float32).to(DEVICE)\n",
    "    mat = torch.matmul(p_norm, s_norm.T)\n",
    "    np.save(cache_path, mat.cpu().numpy())\n",
    "    print(f\"Saved {name} cosine matrix to {cache_path}\")\n",
    "    return mat\n",
    "\n",
    "cos_mpnet = get_cosine_matrix(poem_in[\"mpnet\"], song_in[\"mpnet\"], \"mpnet\")\n",
    "cos_emo   = get_cosine_matrix(poem_in[\"sem_emo\"], song_in[\"sem_emo\"], \"sem_emo\")\n",
    "cos_theme = get_cosine_matrix(poem_in[\"sem_theme\"], song_in[\"sem_theme\"], \"sem_theme\")\n",
    "cos_other = get_cosine_matrix(poem_in[\"sem_other\"], song_in[\"sem_other\"], \"sem_other\")\n",
    "cos_feat  = get_cosine_matrix(poem_in[\"feat\"], song_in[\"feat\"], \"feat\")\n",
    "\n",
    "cos_matrix_t = (\n",
    "    ALPHA * cos_mpnet +\n",
    "    BETA_EMO * cos_emo +\n",
    "    BETA_THEME * cos_theme +\n",
    "    BETA_OTHER * cos_other +\n",
    "    GAMMA * cos_feat\n",
    ")\n",
    "\n",
    "print(\"Combined cosine matrix shape:\", cos_matrix_t.shape)\n",
    "\n",
    "# Build pos/hard/neg pairs from current hyperparameters (always recompute based on thresholds)\n",
    "print(f\"Building pairs with POS_TOPK={POS_TOPK}, HARD_TOPK={HARD_TOPK}, EASY_THRESHOLD={EASY_THRESHOLD}...\")\n",
    "P, S = cos_matrix_t.shape\n",
    "pos_pairs = []\n",
    "hard_pairs = []\n",
    "neg_pairs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # For each poem, get top (POS_TOPK + HARD_TOPK) indices\n",
    "    topk_vals, topk_idxs = torch.topk(cos_matrix_t, k=min(S, POS_TOPK + HARD_TOPK), dim=1, largest=True, sorted=True)\n",
    "\n",
    "    # Build pos and hard lists\n",
    "    for i in range(P):\n",
    "        for j in topk_idxs[i, :POS_TOPK].tolist():\n",
    "            pos_pairs.append((int(i), int(j)))\n",
    "        for j in topk_idxs[i, POS_TOPK:POS_TOPK+HARD_TOPK].tolist():\n",
    "            hard_pairs.append((int(i), int(j)))\n",
    "\n",
    "    easy_mask = cos_matrix_t <= EASY_THRESHOLD\n",
    "    for i in range(P):\n",
    "        low_idxs = torch.nonzero(easy_mask[i], as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "        if low_idxs.size > 0:\n",
    "            sample_ct = min(5, low_idxs.size)\n",
    "            choice = np.random.choice(low_idxs, size=sample_ct, replace=False)\n",
    "            for j in choice:\n",
    "                neg_pairs.append((int(i), int(j)))\n",
    "\n",
    "print(f\"Built pairs -> pos: {len(pos_pairs)} hard: {len(hard_pairs)} easy: {len(neg_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5000 samples/epoch, loader batches: 40\n"
     ]
    }
   ],
   "source": [
    "# Pre-build GPU tensors so batching is instant\n",
    "poem_gpu = {}\n",
    "song_gpu = {}\n",
    "\n",
    "for k in poem_in:\n",
    "    poem_gpu[k] = torch.from_numpy(poem_in[k]).to(torch.float32).to(DEVICE)\n",
    "    song_gpu[k] = torch.from_numpy(song_in[k]).to(torch.float32).to(DEVICE)\n",
    "\n",
    "# Build dataset and loader\n",
    "dataset = PairDataset(pos_pairs, neg_pairs, hard_pairs, size=SAMPLES_PER_EPOCH)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples/epoch, loader batches: {len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_loss(poem_emb, song_emb, temperature=TEMP):\n",
    "    \"\"\"\n",
    "    InfoNCE / contrastive loss for a batch of poem/song embedding pairs.\n",
    "    \n",
    "    Args:\n",
    "        poem_emb: [B, D] poem embeddings\n",
    "        song_emb: [B, D] song embeddings\n",
    "        temperature: scaling for logits\n",
    "    \n",
    "    Returns:\n",
    "        Scalar loss\n",
    "    \"\"\"\n",
    "    # Normalize both\n",
    "    poem_emb = F.normalize(poem_emb, dim=1)\n",
    "    song_emb = F.normalize(song_emb, dim=1)\n",
    "    \n",
    "    B = poem_emb.shape[0]\n",
    "    \n",
    "    # Compute all-pairs similarity: [B, B]\n",
    "    logits = torch.matmul(poem_emb, song_emb.T) / temperature\n",
    "    \n",
    "    # Positives on diagonal, negatives off-diagonal\n",
    "    labels = torch.arange(B, device=poem_emb.device)\n",
    "    \n",
    "    # Symmetric loss: poem->song + song->poem\n",
    "    loss_p2s = F.cross_entropy(logits, labels)\n",
    "    loss_s2p = F.cross_entropy(logits.T, labels)\n",
    "    \n",
    "    return (loss_p2s + loss_s2p) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "4sNEKioCoDl4"
   },
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pos_pairs, neg_pairs, hard_pairs, size):\n",
    "        \"\"\"\n",
    "        Returns poem/song indices for each sample.\n",
    "        size = number of samples per epoch\n",
    "        \"\"\"\n",
    "        self.pos_pairs  = pos_pairs\n",
    "        self.neg_pairs  = neg_pairs\n",
    "        self.hard_pairs = hard_pairs\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Sample random positive pair\n",
    "        i_poem, j_song = self.pos_pairs[np.random.randint(len(self.pos_pairs))]\n",
    "        \n",
    "        # Return indices only (training loop will index the actual data)\n",
    "        return i_poem, j_song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7U7AM1ToG3D"
   },
   "outputs": [],
   "source": [
    "class ProjectionModel(nn.Module):\n",
    "    def __init__(self, p_dims, s_dims, proj_dim):\n",
    "        super().__init__()\n",
    "        p_mp, p_emo, p_theme, p_other, p_ft = p_dims\n",
    "        s_mp, s_emo, s_theme, s_other, s_ft = s_dims\n",
    "        # poem branches\n",
    "        self.poem_mp = nn.Sequential(nn.Linear(p_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.poem_emo = nn.Sequential(nn.Linear(max(p_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_theme = nn.Sequential(nn.Linear(max(p_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_other = nn.Sequential(nn.Linear(max(p_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_ft = nn.Sequential(nn.Linear(p_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.poem_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "        # song branches\n",
    "        self.song_mp = nn.Sequential(nn.Linear(s_mp, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "        self.song_emo = nn.Sequential(nn.Linear(max(s_emo,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_theme = nn.Sequential(nn.Linear(max(s_theme,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_other = nn.Sequential(nn.Linear(max(s_other,1), 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_ft = nn.Sequential(nn.Linear(s_ft, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "        self.song_proj = nn.Sequential(nn.LayerNorm(128+64+64+64+64), nn.Linear(128+64+64+64+64, proj_dim))\n",
    "    def forward_poem(self, p):\n",
    "        mp = self.poem_mp(p[\"mpnet\"])\n",
    "        emo_in = p[\"sem_emo\"] if p_dim_emo>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        theme_in = p[\"sem_theme\"] if p_dim_theme>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        other_in = p[\"sem_other\"] if p_dim_other>0 else torch.zeros(p[\"mpnet\"].shape[0], 1, device=p[\"mpnet\"].device)\n",
    "        emo = self.poem_emo(emo_in)\n",
    "        theme = self.poem_theme(theme_in)\n",
    "        other = self.poem_other(other_in)\n",
    "        ft  = self.poem_ft(p[\"feat\"])\n",
    "        comb = torch.cat([mp, emo, theme, other, ft], dim=1)\n",
    "        z = self.poem_proj(comb)\n",
    "        return F.normalize(z, dim=1)\n",
    "    def forward_song(self, s):\n",
    "        mp = self.song_mp(s[\"mpnet\"])\n",
    "        emo_in = s[\"sem_emo\"] if s_dim_emo>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        theme_in = s[\"sem_theme\"] if s_dim_theme>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        other_in = s[\"sem_other\"] if s_dim_other>0 else torch.zeros(s[\"mpnet\"].shape[0], 1, device=s[\"mpnet\"].device)\n",
    "        emo = self.song_emo(emo_in)\n",
    "        theme = self.song_theme(theme_in)\n",
    "        other = self.song_other(other_in)\n",
    "        ft  = self.song_ft(s[\"feat\"])\n",
    "        comb = torch.cat([mp, emo, theme, other, ft], dim=1)\n",
    "        z = self.song_proj(comb)\n",
    "        return F.normalize(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper utilities for grid search experiments (pair building, training, evaluation)\n",
    "from itertools import product\n",
    "import time\n",
    "import math\n",
    "\n",
    "P_DIMS_GRID = (\n",
    "    poem_gpu[\"mpnet\"].shape[1],\n",
    "    poem_gpu[\"sem_emo\"].shape[1] if poem_gpu[\"sem_emo\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"sem_theme\"].shape[1] if poem_gpu[\"sem_theme\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"sem_other\"].shape[1] if poem_gpu[\"sem_other\"].ndim > 1 else 0,\n",
    "    poem_gpu[\"feat\"].shape[1],\n",
    ")\n",
    "S_DIMS_GRID = (\n",
    "    song_gpu[\"mpnet\"].shape[1],\n",
    "    song_gpu[\"sem_emo\"].shape[1] if song_gpu[\"sem_emo\"].ndim > 1 else 0,\n",
    "    song_gpu[\"sem_theme\"].shape[1] if song_gpu[\"sem_theme\"].ndim > 1 else 0,\n",
    "    song_gpu[\"sem_other\"].shape[1] if song_gpu[\"sem_other\"].ndim > 1 else 0,\n",
    "    song_gpu[\"feat\"].shape[1],\n",
    ")\n",
    "PROJ_DIM_GRID = int(\n",
    "    globals().get(\n",
    "        \"proj_dim\",\n",
    "        getattr(model.poem_proj[-1], \"out_features\", 128) if \"model\" in globals() else 128,\n",
    "    )\n",
    ")\n",
    "\n",
    "def combine_cosine_matrix(weights):\n",
    "    \"\"\"Create weighted cosine matrix using cached per-modality similarities.\"\"\"\n",
    "    return (\n",
    "        weights[\"alpha\"] * cos_mpnet\n",
    "        + weights[\"beta_emo\"] * cos_emo\n",
    "        + weights[\"beta_theme\"] * cos_theme\n",
    "        + weights[\"beta_other\"] * cos_other\n",
    "        + weights[\"gamma\"] * cos_feat\n",
    "    )\n",
    "\n",
    "def build_pairs_from_matrix(\n",
    "    cos_matrix,\n",
    "    pos_topk=POS_TOPK,\n",
    "    hard_topk=HARD_TOPK,\n",
    "    easy_threshold=EASY_THRESHOLD,\n",
    "    easy_samples=5,\n",
    "    rng=None,\n",
    "):\n",
    "    \"\"\"Return positive / hard / easy pairs based on similarity thresholds.\"\"\"\n",
    "    rng = rng or np.random\n",
    "    P, S = cos_matrix.shape\n",
    "    pos_pairs, hard_pairs, neg_pairs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        k = min(S, pos_topk + hard_topk)\n",
    "        if k > 0:\n",
    "            _, topk_idxs = torch.topk(cos_matrix, k=k, dim=1, largest=True, sorted=True)\n",
    "        else:\n",
    "            topk_idxs = None\n",
    "        for i in range(P):\n",
    "            if pos_topk > 0 and topk_idxs is not None:\n",
    "                pos_pairs.extend([(int(i), int(j)) for j in topk_idxs[i, :pos_topk].tolist()])\n",
    "            if hard_topk > 0 and topk_idxs is not None:\n",
    "                hard_pairs.extend([(int(i), int(j)) for j in topk_idxs[i, pos_topk : pos_topk + hard_topk].tolist()])\n",
    "        if easy_threshold is not None:\n",
    "            easy_mask = cos_matrix <= easy_threshold\n",
    "            for i in range(P):\n",
    "                low_idxs = torch.nonzero(easy_mask[i], as_tuple=False).squeeze(-1).cpu().numpy()\n",
    "                if low_idxs.size == 0:\n",
    "                    continue\n",
    "                sample_ct = min(easy_samples, low_idxs.size)\n",
    "                choice = rng.choice(low_idxs, size=sample_ct, replace=False)\n",
    "                for j in choice:\n",
    "                    neg_pairs.append((int(i), int(j)))\n",
    "    return pos_pairs, hard_pairs, neg_pairs\n",
    "\n",
    "def make_loader_for_config(pos_pairs, neg_pairs, hard_pairs, batch_size, samples_per_epoch):\n",
    "    dataset = PairDataset(pos_pairs, neg_pairs, hard_pairs, size=samples_per_epoch)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    return dataset, loader\n",
    "\n",
    "def train_single_config(\n",
    "    loader,\n",
    "    temperature,\n",
    "    lr,\n",
    "    epochs,\n",
    "    patience,\n",
    "    delta,\n",
    "    warmup_epochs,\n",
    "    min_lr,\n",
    "    use_cosine_schedule,\n",
    "    moving_avg_window,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"Train a ProjectionModel with the provided loader and hyperparameters.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    model_local = ProjectionModel(P_DIMS_GRID, S_DIMS_GRID, PROJ_DIM_GRID).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model_local.parameters(), lr=lr)\n",
    "    warm_epochs = min(warmup_epochs, epochs)\n",
    "    warmup_scheduler = None\n",
    "    scheduler_main = None\n",
    "    if use_cosine_schedule and epochs > 0:\n",
    "        warm_epochs = max(1, warm_epochs)\n",
    "        def lr_lambda(epoch):\n",
    "            return min(1.0, (epoch + 1) / warm_epochs)\n",
    "        warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "        t_max = max(1, epochs - warm_epochs)\n",
    "        scheduler_main = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=min_lr)\n",
    "    loss_history, lr_history = [], []\n",
    "    best_loss = math.inf\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        for pidxs, sidxs in loader:\n",
    "            optimizer.zero_grad()\n",
    "            batch_poem = {k: poem_gpu[k][pidxs] for k in poem_gpu}\n",
    "            batch_song = {k: song_gpu[k][sidxs] for k in song_gpu}\n",
    "            poem_out = model_local.forward_poem(batch_poem)\n",
    "            song_out = model_local.forward_song(batch_song)\n",
    "            loss = clip_loss(poem_out, song_out, temperature=temperature)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append(loss.item())\n",
    "        if not epoch_losses:\n",
    "            break\n",
    "        avg_loss = float(np.mean(epoch_losses))\n",
    "        loss_history.append(avg_loss)\n",
    "        window = moving_avg_window if moving_avg_window > 0 else len(loss_history)\n",
    "        smooth_loss = float(np.mean(loss_history[-window:]))\n",
    "        if smooth_loss < best_loss - delta:\n",
    "            best_loss = smooth_loss\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model_local.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if warmup_scheduler and epoch < warm_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        elif scheduler_main:\n",
    "            scheduler_main.step()\n",
    "        lr_history.append(optimizer.param_groups[0][\"lr\"])\n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    train_time = time.time() - start_time\n",
    "    if best_state:\n",
    "        model_local.load_state_dict(best_state)\n",
    "    return {\n",
    "        \"model\": model_local,\n",
    "        \"loss_history\": loss_history,\n",
    "        \"lr_history\": lr_history,\n",
    "        \"best_loss\": best_loss,\n",
    "        \"epochs_trained\": len(loss_history),\n",
    "        \"train_time\": train_time,\n",
    "    }\n",
    "\n",
    "def evaluate_on_triplets(model_local):\n",
    "    if \"human_triplets\" not in globals():\n",
    "        raise RuntimeError(\"human_triplets is not defined in the workspace.\")\n",
    "    model_local.eval()\n",
    "    correct = 0\n",
    "    total = len(human_triplets)\n",
    "    with torch.no_grad():\n",
    "        for p_idx, s1_idx, s2_idx, label in human_triplets:\n",
    "            p_batch = {k: poem_gpu[k][p_idx : p_idx + 1] for k in poem_gpu}\n",
    "            s1_batch = {k: song_gpu[k][s1_idx : s1_idx + 1] for k in song_gpu}\n",
    "            s2_batch = {k: song_gpu[k][s2_idx : s2_idx + 1] for k in song_gpu}\n",
    "            p_z = model_local.forward_poem(p_batch)\n",
    "            s1_z = model_local.forward_song(s1_batch)\n",
    "            s2_z = model_local.forward_song(s2_batch)\n",
    "            sim1 = float((p_z * s1_z).sum().item())\n",
    "            sim2 = float((p_z * s2_z).sum().item())\n",
    "            pred = 1 if sim1 > sim2 else 2\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search runner (toggle RUN_GRID_SEARCH to True to execute all configurations)\n",
    "import json\n",
    "\n",
    "RUN_GRID_SEARCH = True  # Notebook default: execute grid search when this cell runs\n",
    "SAVE_ALL_MODELS = True  # When True, store every trained checkpoint under results/\n",
    "GRID_BATCH_SIZES = [96, 128]\n",
    "GRID_TEMPERATURES = [0.5, 0.7, 0.9]\n",
    "GRID_WEIGHT_CONFIGS = [\n",
    "    {\"name\": \"mpnet_heavy\", \"alpha\": 0.65, \"beta_emo\": 0.08, \"beta_theme\": 0.12, \"beta_other\": 0.05, \"gamma\": 0.10},\n",
    "    {\"name\": \"balanced\", \"alpha\": 0.55, \"beta_emo\": 0.12, \"beta_theme\": 0.15, \"beta_other\": 0.08, \"gamma\": 0.10},\n",
    "    {\"name\": \"semantic_push\", \"alpha\": 0.45, \"beta_emo\": 0.18, \"beta_theme\": 0.20, \"beta_other\": 0.07, \"gamma\": 0.10},\n",
    "    {\"name\": \"structure_boost\", \"alpha\": 0.50, \"beta_emo\": 0.10, \"beta_theme\": 0.12, \"beta_other\": 0.08, \"gamma\": 0.20},\n",
    "    {\"name\": \"other_focus\", \"alpha\": 0.50, \"beta_emo\": 0.10, \"beta_theme\": 0.12, \"beta_other\": 0.18, \"gamma\": 0.10},\n",
    "]\n",
    "GRID_POS_TOPK = [POS_TOPK]\n",
    "GRID_EASY_THRESH = [EASY_THRESHOLD]\n",
    "GRID_SAMPLES_PER_EPOCH = [4000, 6000]\n",
    "MAX_CONFIGS = 60\n",
    "\n",
    "grid_configs = []\n",
    "for bs, temp, weights, pos_k, easy_thr, spe in product(\n",
    "    GRID_BATCH_SIZES,\n",
    "    GRID_TEMPERATURES,\n",
    "    GRID_WEIGHT_CONFIGS,\n",
    "    GRID_POS_TOPK,\n",
    "    GRID_EASY_THRESH,\n",
    "    GRID_SAMPLES_PER_EPOCH,\n",
    "):\n",
    "    cfg = {\n",
    "        \"label\": f\"{weights['name']}_bs{bs}_t{temp:.2f}_spe{spe}\",\n",
    "        \"batch_size\": bs,\n",
    "        \"temperature\": temp,\n",
    "        \"weights\": weights,\n",
    "        \"pos_topk\": pos_k,\n",
    "        \"hard_topk\": HARD_TOPK,\n",
    "        \"easy_threshold\": easy_thr,\n",
    "        \"samples_per_epoch\": spe,\n",
    "        \"lr\": LR,\n",
    "        \"epochs\": min(EPOCHS, 150),\n",
    "        \"patience\": min(EARLY_STOP_PATIENCE, 20),\n",
    "        \"delta\": EARLY_STOP_DELTA,\n",
    "        \"warmup_epochs\": min(WARMUP_EPOCHS, 5),\n",
    "        \"min_lr\": MIN_LR,\n",
    "        \"use_cosine_schedule\": USE_COSINE_SCHEDULE,\n",
    "        \"moving_avg_window\": MOVING_AVG_WINDOW,\n",
    "        \"seed\": 1337,\n",
    "    }\n",
    "    grid_configs.append(cfg)\n",
    "    if len(grid_configs) >= MAX_CONFIGS:\n",
    "        break\n",
    "\n",
    "if not RUN_GRID_SEARCH:\n",
    "    print(f\"Grid search configured for {len(grid_configs)} runs. Set RUN_GRID_SEARCH = True to execute.\")\n",
    "else:\n",
    "    results = []\n",
    "    best_result = None\n",
    "    result_dir = Path(\"results\")\n",
    "    result_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for idx, cfg in enumerate(grid_configs, start=1):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Config {idx}/{len(grid_configs)} :: {cfg['label']}\")\n",
    "        weights = cfg[\"weights\"]\n",
    "        cos_matrix = combine_cosine_matrix(weights)\n",
    "        rng = np.random.default_rng(cfg.get(\"seed\", 0) + idx)\n",
    "        pos_pairs, hard_pairs, neg_pairs = build_pairs_from_matrix(\n",
    "            cos_matrix,\n",
    "            pos_topk=cfg[\"pos_topk\"],\n",
    "            hard_topk=cfg[\"hard_topk\"],\n",
    "            easy_threshold=cfg[\"easy_threshold\"],\n",
    "            easy_samples=5,\n",
    "            rng=rng,\n",
    "        )\n",
    "        _, loader_local = make_loader_for_config(\n",
    "            pos_pairs,\n",
    "            neg_pairs,\n",
    "            hard_pairs,\n",
    "            batch_size=cfg[\"batch_size\"],\n",
    "            samples_per_epoch=cfg[\"samples_per_epoch\"],\n",
    "        )\n",
    "        train_out = train_single_config(\n",
    "            loader_local,\n",
    "            temperature=cfg[\"temperature\"],\n",
    "            lr=cfg[\"lr\"],\n",
    "            epochs=cfg[\"epochs\"],\n",
    "            patience=cfg[\"patience\"],\n",
    "            delta=cfg[\"delta\"],\n",
    "            warmup_epochs=cfg[\"warmup_epochs\"],\n",
    "            min_lr=cfg[\"min_lr\"],\n",
    "            use_cosine_schedule=cfg[\"use_cosine_schedule\"],\n",
    "            moving_avg_window=cfg[\"moving_avg_window\"],\n",
    "            seed=cfg.get(\"seed\"),\n",
    "        )\n",
    "        triplet_acc = evaluate_on_triplets(train_out[\"model\"])\n",
    "        result_row = {\n",
    "            \"label\": cfg[\"label\"],\n",
    "            \"batch_size\": cfg[\"batch_size\"],\n",
    "            \"temperature\": cfg[\"temperature\"],\n",
    "            \"weights\": weights,\n",
    "            \"triplet_acc\": triplet_acc,\n",
    "            \"best_loss\": train_out[\"best_loss\"],\n",
    "            \"epochs_trained\": train_out[\"epochs_trained\"],\n",
    "            \"train_time_sec\": train_out[\"train_time\"],\n",
    "            \"pos_pairs\": len(pos_pairs),\n",
    "        }\n",
    "        results.append(result_row)\n",
    "        checkpoint_name = f\"grid_{cfg['label']}.pt\"\n",
    "        checkpoint_path = result_dir / checkpoint_name\n",
    "        if SAVE_ALL_MODELS:\n",
    "            torch.save(train_out[\"model\"].state_dict(), checkpoint_path)\n",
    "        print(\n",
    "            f\"{cfg['label']} → acc {triplet_acc*100:.2f}% | best loss {train_out['best_loss']:.4f} | checkpoint {checkpoint_name if SAVE_ALL_MODELS else 'n/a'}\"\n",
    "        )\n",
    "        if best_result is None or result_row[\"triplet_acc\"] > best_result[\"triplet_acc\"]:\n",
    "            best_state = {k: v.cpu() for k, v in train_out[\"model\"].state_dict().items()}\n",
    "            best_result = {**result_row, \"state_dict\": best_state}\n",
    "    results_sorted = sorted(results, key=lambda r: r[\"triplet_acc\"], reverse=True)\n",
    "    summary_path = result_dir / \"grid_search_results.json\"\n",
    "    with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results_sorted, f, indent=2)\n",
    "    print(f\"\\nSaved summary to {summary_path}\")\n",
    "    if best_result:\n",
    "        best_path = result_dir / f\"grid_best_{best_result['label']}.pt\"\n",
    "        torch.save(best_result[\"state_dict\"], best_path)\n",
    "        print(\n",
    "            f\"Best config: {best_result['label']} | acc {best_result['triplet_acc']*100:.2f}% | checkpoint → {best_path}\",\n",
    "        )\n",
    "    print(\"Top-5 configs:\")\n",
    "    for row in results_sorted[:5]:\n",
    "        print(\n",
    "            f\"  {row['label']}: acc {row['triplet_acc']*100:.2f}% | loss {row['best_loss']:.4f} | epochs {row['epochs_trained']}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhkjxY/YsXdDuc4G7l52t2",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
